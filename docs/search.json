[
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "C.V.",
    "section": "",
    "text": "For your convenience, you can download a PDF copy of my CV here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zachary Lorico Hertz",
    "section": "",
    "text": "Welcome to my website!\nI am a researcher, political consultant, and data journalist driven by an interest in communities.  In my research, I use geocoded observational data and original survey data to understand questions at the intersection of political behavior, identity politics, local politics, and American political institutions.  I love my friends, talking about political problems, and being outside. Sometimes all at once!\nLearn more about me here, check out my research, or say hi!"
  },
  {
    "objectID": "posts/2021-06-22-dfp-lucid/index.html",
    "href": "posts/2021-06-22-dfp-lucid/index.html",
    "title": "Investigating Concerns about Lucid Theorem Data Quality",
    "section": "",
    "text": "The blossoming use of survey research in political science heightens the need for rigorous investigation into data quality. To obtain samples, academics often rely on survey vendors such as SurveyMonkey, Amazon’s Mechanical Turk (MTurk), and Lucid Theorem. Use of data from Lucid has become increasingly prevalent, and the focus of growing data quality concerns.\nMore recently, Josh Kalla posted a thread on Twitter noting that when running a near-replication of a survey from March 2021 in June 2021, the median response time had dropped over five minutes. This result is particularly troubling, as a dramatic decrease in median response time could indicate extensive satisficing by respondents, colloquially referred to as “speeders,” and potentially induce bias into the results.\nStill, while these findings certainly raise cause for concern, any response time issues between these particular two surveys may reflect nuanced differences in the question battery or result from pure chance. A survey with a static battery of questions fielded consistently and repeatedly via Lucid over a wide time period is the ideal way to clarify whether there have been recent and notable decreases in response time among Lucid’s respondents.\nFortunately, I have access to such a survey: the Data For Progress Covid-19 tracking poll, fielded via Lucid by Brian Schaffner. There have been 25 waves of the poll between April 2020 and May 2021, and besides small modifications has remained almost identical over that time period. I used data from the tracking poll to investigate whether our data from Lucid saw any changes in response time over the fourteen-month period, and check whether the Lucid-provided partisan measure correlated strongly with the ideology question included in the poll.\n\nMedian response time was generally stable\nThe median response time was generally stable until October, when it dropped through the fall and winter, returning to previous levels in the spring. Between April 2020 and May 2021, the median response time to the DFP Covid-19 tracking poll ranged from 12.35 to 14.43 minutes. In the poll’s first eight iterations, response times mostly increased, reaching the poll’s greatest median response time during Wave Eight on June 09, 2020. Over the next eight waves, between June 23 and September 22, the median response time was fairly static and stayed between 13 and 14 minutes. Response times dropped to twelve minutes in October and stayed there over the next six waves into February 2021. The February 09, 2021 wave saw a slight increase in median response time, and the March, April, and May waves all had median response times near the previous mid 13-minute mark. For the most part, the first and third quartiles followed similar trends, suggesting that there were no dramatic changes in the distribution of response times among our Lucid Theorem respondents.\n\nStill, while tracking the median response time over 13 months is a convenient measure to identify whether the proportion of speeders among Lucid respondents have been increasing, we might prefer to examine the full distribution of response times over all 25 waves of the Covid-19 tracking poll to glean more information. I visualized this distribution for each wave below using the {gganimate} package. Plotting the median, as well as the first and third quartiles, helps identify any notable shifts in the distribution of response times.\n\n\n\nUsing correlations to check data quality\nWe can also attempt to measure data quality by testing whether variables that should be correlated based on theory actually are correlated in our data. Lucid provides respondent demographics across several variables, including age, education, ethnicity, gender, household income, party identification and region. I also investigated whether the respondent party identification information provided by Lucid is correlated as expected with respondent-provided political ideology. To provide a baseline, I coded identical political party and political ideology using the 2020 CES, which had a correlation coefficient of 0.668.\nWe see that the correlation between party identification and ideology was higher than 0.5 in a majority of waves, but remains lower than expected from the CES data. There were two notable shifts. The correlation fell, rose, and then dropped again over the five waves fielded between May 5, 2020 and June 9, 2020. There was also a sharp drop in the correlation between Lucid-provided party identification and respondent ideology from 0.594 on September 22, 2020 to 0.391 on October 6, 2020. The correlation has risen steadily since then, and was 0.624 for the wave fielded on May 15, 2021.\n\n\n\nConclusion\nOverall, as the median and quartile measures for response times remain fairly stable over time and follow similar trends, I find limited evidence that the proportion of speeders have recently been increasing among respondents recruited via Lucid Theorem. Additionally, research finds that speeders have a limited effect on data quality, potentially assuaging concerns about external validity even if speeders were becoming more common among data gathered using Lucid Theorem.\nStill, these findings follow important caveats. The data from the DFP tracking poll includes respondents who pass attention checks. Yet an increasing number of survey respondents are failing attention checks, and those who do fail are markedly different from attentive respondents. Speeders may be increasing among the population of Lucid respondents but end up filtered from the data after failing attention checks, and attention checks remain critical to maintaining data quality. To guard against inattentive respondents and continue to monitor for potential declines in response quality among survey vendors, researchers must continue to include attention checks while building in questions and methods to independently audit their data.\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2021,\n  author = {Lorico Hertz, Zachary},\n  title = {Investigating {Concerns} about {Lucid} {Theorem} {Data}\n    {Quality}},\n  date = {2021-06-22},\n  url = {https://zacharylhertz.github.io/posts/2021-06-22-dfp-lucid/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2021. “Investigating Concerns about Lucid\nTheorem Data Quality.” June 22, 2021. https://zacharylhertz.github.io/posts/2021-06-22-dfp-lucid/."
  },
  {
    "objectID": "posts/2021-06-29-survey-package/index.html",
    "href": "posts/2021-06-29-survey-package/index.html",
    "title": "An Introduction to Using the {survey} Package in R",
    "section": "",
    "text": "Survey research commonly relies on weights to reduce bias and produce a representative sample for a given population of interest. Weighted survey data produces a value assigned to each observation in the data that increases or decreases that observation’s influence (or weight) when performing statistical operations using the data.\nCorrectly implementing weights can seem an intimidating challenge to early R users; luckily several packages exist to simplify working with weighted data in R. The package I currently use is {survey}, which I have used to produce several pieces in my work for Data for Progress and the Tufts Public Opinion Lab.\nTo that end, I have written a quick guide to using the {survey} package in R to create weighted proportion tables and plot results using {ggplot2}. This primer uses the Data for Progress Covid-19 tracking poll data and assumes an elementary knowledge of coding in R. This guide was originally written for one of my Tufts Public Opinion Lab colleagues as well as my Political Science Research Methods students, but I hope others benefit from it!\n\nSetup\nTo start, you’ll need to read in the necessary packages and then the data. Beyond {survey} for weighted analysis and {tidyverse} to use ggplot2 to visualize results, I use a few additional packages: {haven}, {magrittr}, and {plyr}. Since my data is from a .dta file, I use {haven} to read the data into R. I also use the function multiply_by() and the pipe operator, %&gt;%, from the {magrittr} package. Finally, when manipulating my plot data I rely on the ddply() function from {plyr}.\nlibrary(haven)\nlibrary(survey)\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(plyr)\ndat &lt;- read_dta(\"dfp_covid_tracking_poll.dta\")\nWeights are generally stored in a column within your dataframe, and may differ depending on which population you are attempting to represent with your data. You should be able to identify the weights and their appropriate variable name using the codebook. Here, we weight to the American adult populations using the variable nationalweight.\nTo use the weights, you first create a survey design object using the svydesign() function from {survey}, and specify the appropriate dataframe and weights.\n# First, create a survey design object for the dataset.\n# Here, my data is 'dat' and weights are 'nationalweight'.\nsvy.dat &lt;- svydesign(ids=~1, data=dat,\n                     weights=dat$nationalweight)\nYou can also create a survey design object using subsets, which can be particularly useful to analyze specific parts of your data. To do so, simply specify the subset instead of your full data in the ‘data’ argument of svydesign().\nTo illustrate, I will compare vaccination likelihood between White Evangelicals and the sample as a whole. Race is represented by the ethnicity variable, where White respondents have a value of 1, and evangelicalism is represented by the pew_bornagain variable, where Evangelicals have a value of 1.\n# Create your white evangelical subset...\nwtevan &lt;- subset(dat, dat$ethnicity==1&dat$pew_bornagain==1)\n\n# ...And create a survey design object for White Evangelicals.\nsvy.evan &lt;- svydesign(ids = ~1, data = wtevan,\n                      weights = wtevan$nationalweight)\nNote that above you use the same weight variable from your full data, in this case nationalweight, but in the weights = argument of svydesign() you have to pull the weight variable from the same dataframe you use in the data = argument.\n\n\nUsing {survey} to create weighted proportion tables\nNow that we have survey design objects, we use them in combination with the svytable() function to apply the weights. The syntax is very intuitive, essentially:\nsvytable(~Var1 + Var2 + ..., design=your.surveydesignobject)\nSimply include which variables you would like to table, separating variables with ‘+’, and specify the appropriate survey design object. I then use prop.table() to convert counts to a proportion, multiply by 100 to create total percentages, round to one digit, and convert the result to an easily-viewable dataframe.\nAs a quick example using multiple variables, I create a table of vaccine likelihood (vax_likely), education (educ), and party identification (pid7) with the following code:\nvax.educ.race &lt;- svytable(~vax_likely + educ + pid7, \n                     design=svy.dat) %&gt;%\n  prop.table() %&gt;%\n  multiply_by(100) %&gt;%  \n# Note that multiply_by() comes from magrittr!\n  round(digits=1) %&gt;%\n  as.data.frame()\n\nhead(vax.educ.race)\n##   vax_likely educ pid7 Freq\n## 1          1    1    1  0.6\n## 2          2    1    1  0.1\n## 3          3    1    1  0.3\n## 4          4    1    1  0.1\n## 5          1    2    1  3.1\n## 6          2    2    1  1.7\nApplying this to our investigation of vaccine likelihood for White Evangelicals compared to national adults, we can create two tables. The first uses the survey design object created with the entire dataset (svy.dat), the other uses the survey design object created for just White Evangelicals (svy.evan).\n# Vaccination likelihood among all American adults\nlikely &lt;- svytable(~vax_likely, design=svy.dat) %&gt;%\n  prop.table() %&gt;%\n  multiply_by(100) %&gt;%\n  round(digits=1) %&gt;%\n  as.data.frame()\n\n# Vaccination likelihood among White Evangelicals  \nlikely.evan &lt;- svytable(~vax_likely, design=svy.evan) %&gt;%\n  prop.table() %&gt;%\n  multiply_by(100) %&gt;%\n  round(digits=1) %&gt;%\n  as.data.frame()\n  \n# Vax likelihood among all American adults\nlikely \n##   vax_likely Freq\n## 1          1 34.7\n## 2          2 22.6\n## 3          3 14.5\n## 4          4 28.2\n# Vax likelihood among White Evangelical adults\nlikely.evan \n##   vax_likely Freq\n## 1          1 29.7\n## 2          2 25.2\n## 3          3 14.6\n## 4          4 30.5\n\n\nPlotting weighted results with {survey} and {ggplot2}\nTo visualize my results, I create a variable labelling each group, then combine the two tables into a single dataframe. I also use ddply() to calculate the halfway point of each proportion and use that position to specify where labels should go on the final plot.\n# Add variable identifying each group\nlikely$group &lt;- \"All respondents\"\nlikely.evan$group &lt;- \"White Evangelicals\"\n\n# Combine into a single dataframe for plotting\nplot &lt;- rbind(likely, likely.evan)\n\n# Create a variable, label_ypos, equal to the halfway point\n# in each bar for specifying labels.\nplot &lt;- ddply(plot, \"group\",\n                   transform, \n                   label_ypos=cumsum(Freq) - 0.5*Freq)\nHaving created a single dataframe, I use ggplot2 as usual to plot my results.\np &lt;- ggplot(plot, \n            aes(x = group, y = Freq, fill = vax_likely)) + \n  geom_bar(stat=\"identity\", \n           position = position_stack(reverse = TRUE)) + \n  coord_flip() + theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5, \n                                  size = 16), \n        plot.caption = element_text(hjust = 1,\n                                    face = \"italic\", size=8),\n        axis.title.x = element_text(size=10), \n        axis.title.y = element_blank(),\n        axis.text.y = element_text(size=10, \n                                   color = \"black\")) + \n  ylab(\"Percent\") + \n  labs(fill=\"Likeliness to get Covid-19 \n  vaccine when available\", \n       caption = \"Zachary L. Hertz | Data: Data For Progress\") +\n  ggtitle(\"White Evangelicals remain skeptical of Covid-19 vaccine\") +\n  scale_fill_manual(labels = c(\"Very likely\", \n                               \"Somewhat likely\", \n                             \"Somewhat unlikely\", \n                             \"Very unlikely\"), \n                    values=c(\"#7aa457\", \n                             \"#b6caa2\", \n                             \"#e4ac9e\", \n                             \"#cb6751\")) +\n  geom_text(aes(y=label_ypos, label=Freq), \n            color=\"white\", size=3.5)\np\n\n\n\nConclusion\nThe {survey} package is a flexible and powerful tool to use weights in survey analysis and visualization. Using the svydesign() and svytable() functions is an easy way to create weighted proportion tables and examine representative data. As I often rely upon public tutorials when learning new skills in R, I hope this guide proves useful to any future researchers hoping to grow their survey analysis skills using R!\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2021,\n  author = {Lorico Hertz, Zachary},\n  title = {An {Introduction} to {Using} the `\\{Survey\\}` {Package} in\n    {R}},\n  date = {2021-06-29},\n  url = {https://zacharylhertz.github.io/posts/2021-06-29-survey-package/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2021. “An Introduction to Using the\n`{Survey}` Package in R.” June 29, 2021. https://zacharylhertz.github.io/posts/2021-06-29-survey-package/."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Truth Hertz",
    "section": "",
    "text": "This blog tracks a number of short data-driven posts I have written over the years analyzing survey data, methodology, and electoral trends. I may also throw other musings here when I have the time to neglect my research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProof Advice and Strategies for Political Scientists\n\n\nAdvice for social scientists learning about writing proofs for the first time.\n\n\n\ngame theory\n\nformal models\n\nproofs\n\n\n\n\n\n\nJan 29, 2026\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting “Educational Polarization: A White Phenomenon?” in the Wake of the 2024 Election\n\n\nTracking Democratic de-identification and vote attrition across racial groups.\n\n\n\nelectoral analysis\n\nR\n\nCES\n\neducational polarization\n\nracial polariation\n\ncollege education\n\n\n\n\n\n\nAug 22, 2025\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nIn WAR, There Are No Winners But All Are Lou-sers\n\n\nIs Nancy Pelosi really one of the weakest Democratic candidates for Congress - or was her opponent really one of the strongest Republican candidates?\n\n\n\nelectoral analysis\n\nR\n\nCensus data\n\nAsian Americans\n\nturnout\n\nCongress\n\nrace and ethnicity\n\n\n\n\n\n\nAug 15, 2025\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Can Survey Data Tell Us About Ideological Differences Between Black Voters and Black Nonvoters?\n\n\nHow much do Black 2020 voters differ from Black 2020 nonvoters, and what does this mean for the 2024 election?\n\n\n\nelectoral analysis\n\nR\n\nCES\n\nBlack Americans\n\nturnout\n\nrace and ethnicity\n\n\n\n\n\n\nNov 5, 2024\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Survey Weights in R Using Census Data\n\n\nBoy, you’re gonna cre-ate that weight: A quick guide to creating original survey weights using Census data in R.\n\n\n\nR\n\ntutorial\n\nsurvey\n\ntidyverse\n\nsurvey data\n\nACS\n\nCensus\n\n\n\n\n\n\nMay 16, 2022\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nHow Sensitive are Partisans to Out-Party Cues?\n\n\nAn experiment testing if out-party cues still move policy preferences.\n\n\n\nR\n\nparty cues\n\nelite cues\n\npartisan polarization\n\npolicy learning\n\n\n\n\n\n\nDec 16, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nEducational Polarization: A White Phenomenon?\n\n\nEducational polarization may not be limited to white voters.\n\n\n\nelectoral analysis\n\nR\n\nCES\n\neducational polarization\n\nracial polariation\n\ncollege education\n\n\n\n\n\n\nNov 23, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nEstimates of Youth Turnout Have Recently Diverged\n\n\nUsing multiple data sources to investigate age-based turnout rates.\n\n\n\nR\n\nCES\n\nCIRCLE\n\nyouth voting\n\nvoter turnout\n\n\n\n\n\n\nAug 6, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nTracking the Drop in News Interest\n\n\nData shows a decline in news interest is consistent across party lines, not partisan\n\n\n\nR\n\nvoter analysis\n\nnews interest\n\nmedia attention\n\nsurvey data\n\n\n\n\n\n\nJul 13, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the CES to Examine Young Voters\n\n\nHave age-based turnout gaps persisted?\n\n\n\nelectoral analysis\n\nR\n\nCES\n\nCIRCLE\n\nyouth voting\n\nvoter turnout\n\n\n\n\n\n\nJul 6, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Using the {survey} Package in R\n\n\nA quick guide to implementing and using survey weights in R.\n\n\n\nR\n\ntutorial\n\nsurvey\n\ntidyverse\n\nsurvey data\n\n\n\n\n\n\nJun 29, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Concerns about Lucid Theorem Data Quality\n\n\nHas Lucid Theorem declined in quality due to Covid-19?\n\n\n\nsurvey methodology\n\nData For Progress\n\nLucid\n\n\n\n\n\n\nJun 22, 2021\n\n\nZachary Lorico Hertz\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-05-16-survey-weights/index.html",
    "href": "posts/2022-05-16-survey-weights/index.html",
    "title": "Creating Survey Weights in R Using Census Data",
    "section": "",
    "text": "In survey research, the composition of a sample may differ notably from the population being modeled across important characteristics (e.g. race, age, education, party identification). These sampling errors often reflect systematic bias which can pose a threat to accuracy and the researcher’s ability to make inferences using the data, especially if the error is correlated with the variables of interest.\nIn response, researchers often construct “post-stratification weights” — values assigned to each observation which can be used to correct for sampling error and match the sample to the population on key characteristics. The idea is simple: by increasing the influence of under-represented units and likewise decreasing the influence of over-represented units, researchers can create a more representative sample. This is particularly important given the dramatic increase in the use of online opt-in (or “nonprobability”) samples.\nAn important implication is that you can only construct post-stratification weights using characteristics that are both measured in your data and known for the population; put more simply, if we want to make our sample reflect the population, we have to know what the population looks like! Thus, the American Commmunity Survey (ACS), a premier data source with detailed population information, is an incredible resource to construct population targets for survey weighting.\nLast year, I created survey weights for a project fielded with the Tufts Public Opinion Lab, but the task proved to be fairly involved. First, accessing ACS data requires navigating the Census Bureau’s fairly labyrinthine website. In addition, the size of the national ACS files – totaling over 10 gigabytes – is far beyond what my computer’s memory could possibly handle and crashed R Studio the first time I tried to read them in.\nIn this blog post, I create weights for a simplified version of the TPOL data. I walk through the process of accessing ACS data and using it to construct survey weights using R. I wrote this piece for myself, future lab students, and anyone interested in learning how to access ACS data and use it to create survey weights in R.\nThis post assumes familiarity with the basic concept of post-stratification weights and their uses; those in search of additional reading on weighting are directed to this handy piece on different weighting methods by Pew. While there are multiple weighting methods, the {anesrake} package allows for accessible and automated raking so I use this method to create the weights. To follow along, you will need a basic working knowledge of R. You’ll also use the {data.table}, {survey}, and {tidyverse} packages so be sure to install those by running install.packages() in the console as needed if you haven’t installed them already."
  },
  {
    "objectID": "posts/2022-05-16-survey-weights/index.html#a-quick-note-on-acs-time-periods",
    "href": "posts/2022-05-16-survey-weights/index.html#a-quick-note-on-acs-time-periods",
    "title": "Creating Survey Weights in R Using Census Data",
    "section": "A quick note on ACS time periods",
    "text": "A quick note on ACS time periods\nRemember, the ACS provides estimates for a specific given time period: one year, three years, or five years. It is critical to note that 1-year estimates are not calculated as an average of 12 monthly values (and similarly, the 5-year estimates are not calculated as the average of 60 monthly values, nor as the average of five individual 1-year estimates).\nInstead, the ACS collects survey data continuously, nearly every day of the year and then aggregates the results over the specific time period, spread evenly to avoid placing uneven weight on any given month or year within the period. For ACS 1-year data, this time period is the calendar year, so the 2019 ACS 1-year estimate covers January 2019 to December 2019. For ACS 5-year data, this time period is five calendar years, so the 2019 ACS 5-year estimate covers January 2015 to December 2019.\nThis creates a tradeoff for researchers choosing between 1-year and 5-year estimates. 1-year data is the most current, but 5-year data can generally be more reliable due to the larger sample size. If both estimates are available for your year in question, which one should you use?\nFor rapidly changing geographic areas, 1-year data are best as the current data is more likely to show yearly fluctuations, but are only available for geographic areas with at least 65,000 people. If you are hoping to illustrate a smooth trend, however, 5-year data may be best since the 5-year periods overlap. Above all, you must consistently use the same estimate so be sure to pick either 1-year estimates or 5-year estimates (or 3-year estimates, if applicable)1 and stick with them.\nFor this post, I will be using the 5-year data. Regardless of which period you choose, you should be in a directory filled with .zip files, following the general path:\nwww2.census.gov/programs-surveys/acs/data/pums/{YEAR}/{1-Year/5-Year}\nHow do you interpret these zip files, to pick the appropriate data? Their names are a construction using three important features of the data:\n{file format}_{record type}{state}.zip\n“File format” should take on two values: ‘unix’, denoting SAS datasets, and ‘csv’, denoting comma separated value files. “Record type” is either ‘h’, denoting housing files, or ‘p’, denoting person files. Finally, the file name includes the relevant two-letter state abbreviation code, with the abbreviation “us” denoting the nationwide data.\nI prefer to work with the .csv files. Because I am constructing weighting targets for the population of all American adults, I need the person record type for the “us” geography. So, I find “csv_pus.zip” and download the file. Once you download the file, unzip it (on Mac, you can right click and open with Archive Utility). You should be able to see a README .pdf file, and then your .csv data. If you are using the five-year 2019 U.S. data, you will see four .csv files (psam_pusa.csv, psam_pusb.csv, psam_pusc.csv and psam_pusd.csv). Move the folder to an appropriate working directory2 where you can access the data when you start constructing weights in R."
  },
  {
    "objectID": "posts/2022-05-16-survey-weights/index.html#footnotes",
    "href": "posts/2022-05-16-survey-weights/index.html#footnotes",
    "title": "Creating Survey Weights in R Using Census Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhile somewhat irrelevant to our purposes here, I wanted to note that ACS 3-year estimates have been discontinued and are only available for the 2005-2007, 2006-2008, 2007-2009, 2008-2010, 2009-2011, 2010-2012 and 2011-2013 periods.↩︎\nBeginners in R looking to review working directories can refer to the segment beginning at 04:49 in the R basics video I created for Tufts students.↩︎\nIf this sounds like gibberish to you, no worries! Maybe check out this overview of lists and vectors.↩︎\n[Photo by visuals on Unsplash.]↩︎"
  },
  {
    "objectID": "posts/2021-07-06-ces-young-voters/index.html",
    "href": "posts/2021-07-06-ces-young-voters/index.html",
    "title": "Using the CES to Examine Young Voters",
    "section": "",
    "text": "July 1 marked 50 years since the ratification of the 26th Amendment to the United States Constitution, which legally extended the right to vote to those over the age of 18. Young voters have played a vital – at times, even decisive – role in elections since. But decades after the franchise was extended to 18-, 19-, and 20- year-olds, how does their voting rates compare to American adults overall?\nYouth have historically voted at lower rates than older voters and while some evidence suggests these turnout disparities have declined in recent elections they still remain, in part due to inadequate voter registration efforts targeted at the youngest voters and particularly high barriers to voting. As voting may be habit-forming, understanding to what extent these inequities persist among young voters is critical to rectifying them, working towards an evenly engaged electorate, and building lifelong voters.\nThe Center for Information & Research on Civic Learning and Engagement (CIRCLE) at Tufts University is one of the leading sources of research on young voters. Their research generally defines youth as those under 30, however, a broader group than those 18-20 affected by the 26th Amendment, and their data sources are unfortunately not public. Instead, I turn to the Cooperative Election Study (CES), as the premier large-scale academic survey project aimed at studying the American Electorate. The CES has over 50,000 respondents each year in its representative sample; each wave since 2010 has included over 700 respondents between ages 18 and 20, though this number has dropped in the two most recent waves.\n\nWhile the CES includes voting data matched to the Catalist LLC voter file, the 2020 validated vote data has not been released. Until then, I use the self-reported voting data from the CES to investigate, and will replicate my analysis when validated voting data from all CES waves are made publicly available. As a result, my findings come with the important caveat that self-reported measures consistently overestimate turnout.\n\nThe voter registration gap between youth and older voters remains\nWhen comparing voter registration and voter turnout, it is important to note that presidential and midterm elections should not be directly compared, as voter engagement is higher in presidential elections than midterm elections.\nCES data from the past three midterm elections (2010, 2014, and 2018) shows that the gap in voter registration numbers between the 18-20 year-old cohort and all adults has been persistent. In 2010, 81.5 percent of adults said that they were registered to vote where just 57.1 percent of 18-20 year-olds did, a difference of 24.4 percentage points. While the overall percent of adults registered to vote rose slightly to 82.2 percent in 2014, the number of youth who said they were registered to vote dropped to 51.2 percent, widening the voter registration gap to 31 percent. But in 2018 overall voter registration rose to 83.3 percent and youth voter registration rose with it to 58.8 percent, returning the voter registration gap to 24.5 percent.\n\nThe past three presidential elections (2012, 2016, and 2020) followed a similar yet opposite trend. 76 percent of all adults were registered to vote in 2012 while 57.3 percent of 18-20 year-olds were, a difference of 18.7 percentage points. In 2016 these numbers jumped noticeably: 81.6 percent of adults and 69.3 percent of 18-20 year-olds were registered to vote, closing the gap to just 12.3 percent. But in 2020, youth voter registration dropped slightly to 65.4 percent while overall voter registration rose to 84.3 percent, bringing the voter registration gap back to 18.9 percent, near its 2012 levels.\n\n\nThe turnout gap in midterm elections has decreased, but remains in presidential elections\nCES self-reported vote data shows that the voter turnout gap between 18-20 year-olds and all adults is highest in midterm elections, but has consistently decreased since 2010. 58.9 percent of all adults but just 16 percent of youth reported voting in 2010, a difference of almost 43 percentage points. Self-reported voting increased ten percentage points to 68.8 percent among all adults in 2014 while more than doubling among youth to 35 percent, decreasing the gap to 33.8 percent. By 2018, which saw 72.8 percent of adults report voting, 45 percent of youth ages 18-20 reported voting, bringing the difference in midterm elections to its lowest gap of 27.8 percentage points.\n\nIn presidential elections, the gap in self-reported voting between 18-20 year-olds and all adults is smaller, but has not followed a consistent pattern between 2012 and 2020. In 2012, 72.6 percent of adults but just 54 percent of 18-20 year-olds reported voting, a difference of 18.6 percentage points. Self-reported voting jumped in 2016: 77.4 percent of all adults and 60.3 percent of youth said they voted, decreasing the gap to just 17.1 percent. While self-reported voting increased to 78.6 percent among all adults in 2020, however, only 55.4 percent of 18-20 year-olds reported voting, deepening the turnout gap to 23.2 percentage points.\n\n\nConclusion\nOn the 50th anniversary of extending the franchise to Americans between the ages of 18 and 20, CES data shows that turnout gaps between the youngest Americans and all adults remain but may be decreasing. Gains in youth voter turnout have been especially pronounced in midterm elections, which see lower voter turnout than presidential elections, suggesting that while turnout disparities have not been completely eliminated, efforts to engage the youngest voters in the less-engaged midterm congressional elections may have been successful.\nThese findings are subject to the normal limitations of using survey data to estimate voter turnout. As relying on self-response data often overestimates turnout, I hope to replicate this analysis using the CES validated vote data once the 2020 wave is released.\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2021,\n  author = {Lorico Hertz, Zachary},\n  title = {Using the {CES} to {Examine} {Young} {Voters}},\n  date = {2021-07-06},\n  url = {https://zacharylhertz.github.io/posts/2021-07-06-ces-young-voters/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2021. “Using the CES to Examine Young\nVoters.” July 6, 2021. https://zacharylhertz.github.io/posts/2021-07-06-ces-young-voters/."
  },
  {
    "objectID": "posts/2025-08-22-educational-polarization-redux/index.html",
    "href": "posts/2025-08-22-educational-polarization-redux/index.html",
    "title": "Revisiting “Educational Polarization: A White Phenomenon?” in the Wake of the 2024 Election",
    "section": "",
    "text": "As usual, you can find the code to replicate this analysis in a GitHub repository linked here.\nRecent analysis by The New York Times1 declared that Democrats are facing a “voter registration crisis”: across states that track partisan voter registration, Democrats have lost ground in the share of voters affiliated with the party. Does this hold for the electorate writ large?\n1 This is a gift link!This also reminded me of a previous blog post. In 2021, I wrote a piece showing that while Americans without a college degree of all races were increasingly unlikely to identify as Democrats, educational polarization in vote choice was largely limited to white Americans. In 2024, is this still true? I revisit these questions using the cumulative CES Common Content dataset prepared by Shiro Kuriwaki.\nThe CES data reveals a consistent pattern: across all racial groups, Americans without college degrees identify less strongly as Democrats than their college-educated counterparts. Moreover, this education gap in Democratic identification has widened since 2020 for every racial demographic. Notably, non-college-educated Hispanic and Black Americans have shown steep increases in identification as Independents or with no particular party, a trend that has accelerated from 2020 to 2024. The headline finding is the same as the 2021 post: these voters are moving away from affiliating with the Democratic Party rather than toward the Republican Party.\nThe notable puzzle from the 2021 piece, though, was that the emerging degree divide in Democratic affiliation was not accompanied by a degree divide in presidential vote choice for Black and Hispanic voters. In 2024, however, there is evidence that the degree divide may finally be emerging when it comes to Black and Hispanic presidential vote choice.\n\nSince 2012, Americans are less likely to identify as Democrats\nTo start, because partisan voter registration has a number of issues2 and because it always helps to consider trends in the aggregate, I plot general partisan identification for all American adults between 2008 and 2024. I also make one important analytical change from the 2021 piece: rather than just considering people who explicitly identify as Independents, I group Independents and those who opt not to identify with either the Democratic or Republican parties.3\n2 A topic likely covered in detail elsewhere by more involved authors; these include the fact that not every state requires partisan registration, that voters often change their voting behavior before re-registering with the party, that some members in one party living in a safe state for their unfavored party might want to participate in that party’s closed primary, etc.3 I think this is defensible for a number of reasons, primarily because the question used allows people to identify as leaning towards the Democratic or Republican Parties. As a result, the remaining respondents have made pronounced and conscious decisions to not identify with either party. This leads to some small changes in results for later plots.\n\n\nTracking party identification in presidential years since the CES’s first year reveals a strong and steady decrease in Democratic Party identification has actually tapered somewhat in 2024. Click to expand.\n\n\nWe can see that most notably, while in 2012 half of American adults identified with the Democratic Party, by 2024 just 41.5 percent identified as Democrats. In the same period, the share of adults identifying with the Republican Party grew from 35.6 to 39.7 percent. The share of adults who identified either as Independents or did not identify with the two major parties grew from 14.2 percent in 2012 to a peak of 19.9 percent in 2020, falling slightly in 2024 to 18.7 percent.\n\n\nSince 2020, both Black and Hispanic Americans have undergone Democratic attrition and Republican affiliation\nWhen breaking this out by race, we see a great deal of variation in the aggregate trends. While roughly even shares of white Americans identified with both the Democratic and Republican Parties, identification with the Republican Party rose 5 percentage points and identification with the Democratic Party fell 6 percentage points by 2024. Over this time period, the share of white Americans who identified as Independents or chose not to affiliate rose slightly from 14.2 percent in 2012 to 17.7 percent in 2016, but returned to 14 percent in 2024.\n\n\n\n2024 saw significant increases in the share of Black and Hispanic Americans who identify with the Republican Party. Click to expand.\n\n\nMore than 50 percent of Asian Americans identified with the Democratic Party in 2008, and the share actually increased slightly to 55 percent in 20124 before dropping to 47.8 percent in 2020 and recovering slightly to 49.7 percent in 2024. The share of Asian Americans who identify as Republicans and the share of Asian Americans who identify as Independents or do not identify with either party is about evenly split and stable, hovering around 25 percent for the entire period.\n4 Noting, of course, that there’s relatively wide error bars due to sample size constraints.The share of Black Americans who identify with the Democratic Party peaked at 86 percent in 2012, but has fallen precipitously in every election since. In 2024, 63.2 percent of Black American adults identified with the Democratic Party. In the same period, the share of Black adults who identify with the Republican Party has tripled, from 4 percent in 2012 to 12 percent in 2024. The share of Black adults who identify as Independents or eschew partisan identification altogether has also risen steeply, from about 10 percent in 2012 to nearly 25 percent in 2024.\nThere was a similar decline in the share of Hispanic Americans who identify with the Democratic Party: in 2012, 58.8 percent of Hispanic adults identified as Democrats but in 2024 just 45.4 percent did. The share of Hispanic Americans who identify with the Republican Party has always been higher than the share of Black Americans or Asian Americans who identify with the GOP; despite this, Republican Party identification among Hispanic Americans rose 20 percent between 2012 and 2024, from 22.4 to 27 percent. The truly striking shift was among the share of Hispanic Americans who identify as Independents, which nearly doubled from 14.6 percent in 2012 to 27.6 percent in 2024.\n\n\nDegree divide in Democratic Party affiliation widens further for Black and Hispanic Americans, with some mean reversion among white and Asian Americans\nHas the declining share of Black and Hispanic Americans identifying with the Democratic Party been driven by a continuation of the emerging degree divide I wrote about in 2021? My updated plot shows that the answer is a conditional ‘yes.’\n\n\n\nThe previous degree divide in Democratic Party affiliation appears to have closed somewhat among Asian and white Americans, but accelerated among Black and Hispanic Americans even as Democrats lost ground among college-educated Black and Hispanic Americans. Click to expand.\n\n\nAs I noted previously, there were no diploma divides in the share of self-identified Democrats in 2008 and 2012 for both Black Americans and Hispanic Americans; by 2020, however, as Democratic self-identification declined among those without a college education, education divides emerged and this trend continued into 2024. In 2024, there was a 12.6 percentage point difference in Democratic Party identification among Hispanic Americans with a college degree and those without one; there was also a 13.8 percentage point difference in Democratic Party identification among Black Americans with a college degree and those without one.\nThis trend is contrasted with Asian and white Americans, where educational divides already had appeared in 2012,5 widened in 2016 and 2020, but ended up receding a bit in 2024. They still persist, though: 52.7 percent of college-educated Asian Americans identified as Democrats in 2024, while 41.2 percent of Asian Americans without a degree identified with the same party, a 11.5 percentage point difference.\n5 As I noted in 2021, the relatively small sample size of Asian Americans in the CES creates high uncertainty in the point estimates, so it remains important to caveat the educational differences in 2008 and 2012 among Asian Americans as not statistically significant. Still, in the following years these differences grew and following 2016 the difference in the point estimates for college-educated and non college-educated Asian Americans’ Democratic party identification are statistically significant.\n\nStill no degree divide evident when it comes to Republican Party affiliation among non-white Americans, though 2024 saw a continued move to the party among Black and Hispanic Americans\nThere is strong evidence that Americans of all races without a college degree are increasingly less likely to self-identify as Democrats. But where are these people going, and are the patterns similar across racial groups? Again, I examine whether attrition in Democratic party affiliation among Americans without a college education is driven by switching to the Republican Party, or a general disaffiliation with the two major parties.\n\n\n\nBlack and Hispanic Americans have increasingly identified as Republicans in the Trump era, with no apparent degree divides for non-white Americans.\n\n\nA few interesting updates emerge from including the 2024 data. First, while the 2008-2020 period generally saw a decline in Republic Party affiliation for Asian, Hispanic, and white Americans, 2024 saw an increase in Republican identification among college-educated Americans of all races.\nAlso notable is that while overall just 8.6 percent of Black Americans identify as Republicans, the share of Black Americans (both those with college degrees and those without college degrees) who identify as Republicans has been steadily increasing since 2012.\nHispanic Americans, meanwhile, had somewhat of an unusual pattern emerge. From 2008 to 2016, more college-educated Hispanic Americans identified with the Republican Party than Hispanic Americans without college degrees. In 2020, however, this gap narrowed as college-educated Hispanic Americans decreased slightly and non college-educated Hispanic Americans increased in Republican identification. In 2024, slightly higher shares of both groups identified with the GOP and the former diploma divide has become statistically insignificant.\nThe share of white Americans without a college degree who identify as Republicans remains much noticeably higher in the modern era than in 2008, at 52 percent, and as noted previously white Americans with a college degree increased in GOP identification between 2020 and 2024 by more than any other point since 2008.\n\n\nSince 2012, there have been massive increases in the share of Black and Hispanic Americans without a college degree who identify as Independents\nHere, my analytic decision to group Independent identifiers with people who do not identify with either the Democratic or Republican Party creates important differences from my 2021 analysis. Again, see the previous footnote6 for discussion on this decision.\n6 I think this is defensible for a number of reasons, primarily because the question used allows people to identify as leaning towards the Democratic or Republican Parties. As a result, the remaining respondents have made pronounced and conscious decisions to not identify with either party. This leads to some small changes in results for later plots.The attrition in the share of Hispanic and Black Americans with a college degree who identify with the Democratic Party seems to be driven somewhat by a large increase in identifying as Independents; these groups all increasingly identified as Independents between 2008 and 2024, by which nearly one in five Hispanic Americans with a college degree and one in five Black Americans with a college degree do not identify with either party.\nAmong non-white Americans without a college education, disaffiliation from both political parties is on the rise while appearing generally stable among white Americans. It is important to note that while the estimate for the share of Asian Americans without a college degree who identified as Independents seems to have increased between 2008 and 2024, the previously-mentioned sample size produces large standard errors and these differences can not be seen as statistically significant.\n\n\n\nSince 2012, Black and Hispanic Americans have increasingly identified as Independents or opted out of partisan affiliation, especially those without a college education. Click to expand.\n\n\nAgain, these trends are remarkable for Black and Hispanic Americans without a college education. In 2008, just 13.9 percent of Black Americans without a college education identified as Independents or did not identify with the Democratic or Republican Party. By 2024, this had risen to nearly 31 percent — nearly one in three. Similarly, in 2012 about 17 percent of Hispanic Americans without college degrees did not identify with one of the two major political parties. By 2024, this number nearly doubled to 35 percent.\n\n\nEducational polarization in vote choice is still driven by nonhispanic whites…for now\nAs before, if you believe politics is for power then you might care less about party identification than actual vote choice. To do this, I use validated voters in the CES and their survey responses to the presidential vote choice question. Splitting presidential support for Democratic candidates by race and education over the 2008 to 2024 period leaves us with some interesting findings in an update from 2024.\nWhile between 2008 and 2020 there appeared to be little variation in Hispanic support for the Democratic presidential candidate by education, for the first time the Democratic candidate won a smaller share of Hispanic Americans without a college degree than Hispanic Americans with a college degree, though we cannot conclude that the difference is statistically significant.\n\n\n\nAs in 2020, there is not a statistically significant degree divide for non-white Americans. Click to expand.\n\n\nAnother interesting update is that while 2020 marked a slight and statistically significant drop in Democratic support from 2012 for Black Americans, 2024 marked a rapid erosion in Democratic support that exceeded the decline from the previous eight years. This drop was equally pronounced along educational lines.\nAgain, due to large error bars I hesitate to make strong conclusions about the patterns observed among Asian Americans’ vote choice in the CES when broken out by education, but I note that the education gap that emerged in 2020 appeared to hold in 2024.\nFinally, we also note an interesting and slight reversion to the mean among non-hispanic white Americans, who are frequently cited as the drivers of educational polarization. The Democratic vote share among college-educated whites dropped about 3 percentage points while the vote share among whites without a degree rose about 2 percentage points, closing what was previously a 22 percentage point gap by five percentage points.\n\n\nConsidering vote intent (including nonvoters) suggests educational polarization has affected vote choice\nOne analytical trick that the CES allows us to do is to consider vote intent. Because the CES is a survey, it includes data on the preferred candidates for individuals who never showed up to vote. I reprise the previous plot, this time including responses from non-voters. Suddenly, we can see that a sharp educational polarization in vote preference among nonwhite Americans began in 2020 and intensified in 2024.\n\n\n\nConsidering vote preference, however, shows considerable degree divides. Click to expand.\n\n\nThis analytical move is sharpest for Hispanic Americans; in 2016 and even 2020 there was not much of a difference in Democratic vote preference between those with college educations and those without. By 2024, though, there was a nearly 16 percentage point diploma divide in the Democratic vote preference among Hispanic Americans. Similarly, in 2016 about 80 percent of Black Americans, both with and without a college degree, intended to vote for Democrat Hillary Clinton for president. In 2020, 77.5 percent of Black Americans with a college degree intended to vote for Joe Biden while 68.5 percent of Black Americans without a college degree intended to vote for him, marking about a 9 percentage point diploma divide. This gap narrowed to 7 percentage points in 2024, but persisted.\n\n\nConclusion\nThere appear to be growing educational divides in party identification among Americans of all races, with the trends accelerating significantly between 2020 and 2024. Most notably, Democratic Party identification has declined precipitously among Black and Hispanic Americans without college degrees, falling to historic lows by 2024. While this educational gap in Democratic affiliation has widened dramatically for these groups, it has actually narrowed somewhat among white and Asian Americans.\nThe key finding is that Americans without college degrees across all racial groups are moving away from the Democratic Party rather than toward the Republican Party. Black and Hispanic Americans without college degrees are increasingly identifying as Independents or choosing not to affiliate with either major party, with nearly one in three Black Americans and more than one in three Hispanic Americans without degrees now falling into this category.\nFor the first time since these trends began, there are signs that educational polarization may finally be emerging in actual vote choice among non-white Americans, particularly Hispanic voters. When including vote intent from non-voters, the educational divides become even more pronounced, suggesting these shifts in party identification may be precursors to broader changes in electoral behavior.\nThese patterns represent a fundamental realignment in American political coalitions. The Democratic Party’s traditional strength among voters of color is increasingly concentrated among college-educated members of these communities, while non-college-educated Americans of all races are becoming more politically homeless—disaffiliating from both major parties rather than switching allegiances. Understanding and responding to this trend of political disengagement will be crucial for both parties’ future electoral prospects.\n\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2025,\n  author = {Lorico Hertz, Zachary},\n  title = {Revisiting “{Educational} {Polarization:} {A} {White}\n    {Phenomenon?}” In the {Wake} of the 2024 {Election}},\n  date = {2025-08-22},\n  url = {https://zacharylhertz.github.io/posts/2025-08-22-educational-polarization-redux/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2025. “Revisiting ‘Educational\nPolarization: A White Phenomenon?’ In the Wake of the 2024\nElection.” August 22, 2025. https://zacharylhertz.github.io/posts/2025-08-22-educational-polarization-redux/."
  },
  {
    "objectID": "posts/2021-07-13-news-interest/index.html",
    "href": "posts/2021-07-13-news-interest/index.html",
    "title": "Tracking the Drop in News Interest",
    "section": "",
    "text": "As cable news viewership dropped over the first half of 2021, political commentators were quick to attribute this drop in news interest to the Biden administration. But the first half of 2021 has also seen the Covid-19 pandemic – one of the largest news stories in 2020 – rapidly drop in salience since January thanks to falling infection rates and the largely successful vaccine rollout. As a result, it remains difficult to determine what role the Biden administration and the decreased need to closely follow the pandemic have played as potential drivers of the drop in news interest. I used the Data for Progress Covid-19 Tracking Poll to investigate.\n\nShare of Americans who follow politics “most of the time” fell 15 percent consistently\nThe Data for Progress Covid-19 Tracking Poll, with 25 waves since April 2020, has included a number of questions tracking Americans’ opinions on politics and the pandemic. As part of the survey, respondents answer a question tracking general news engagement:\n\nSome people follow what’s going on in government and public affairs most of the time, whether there’s an election going on or not. Others aren’t as interested. Would you say you follow what’s going on in government and public affairs…\n\nMost of the time\nSome of the time\nOnly now and then\nHardly at all\n\n\nThe share of American adults who say they follow politics “most of the time” dropped from 41.8 percent in January to 35.5 percent in May, marking a 15 percent decline in the highest level of news engagement. In the same time period, the share of those who follow politics “some of the time” and “hardly at all” both increased 3 percentage points, while the share of those who follow politics “only now and then” remained relatively stable.\n\n\n\nShare of Americans who closely follow political news have declined 15 percent since January\n\n\nIf this drop in the share of highly engaged Americans is driven mainly by the effects of the Biden administration, we might expect to see the trend in news interest differ among partisan lines. The data does not reflect a political difference in changing news interest, however. Breaking the sample down by party identification, presidential vote, and strength of partisan identification, we see a consistent 15 percent decline in the highest level of news engagement between January and May.\n\n\n\nPolitical news interest by party identification\n\n\nDemocrats and Republicans had similar trends in the levels of their news interest between October 2020 and January 2021. But while the share of Republicans who followed political news “most of the time” immediately started decreasing from 47.3 percent in January 2021 to 39.8 percent in May 2021, the share of Democrats who were highly-engaged followers hovered around 47 percent until March 2021, but declined to 38 percent by May.\nWe might also expect that any observable effects of the Biden administration on news interest are conditional on having voted for or against his presidency. Unfortunately, the number of nonvoters in the sample is too small to draw reliable conclusions from, but we might imagine that news interest changed differently among Biden voters, who might become less engaged under an in-party administration, and Trump voters, who suddenly find themselves in the outparty. But while total levels of those most interested in following government affairs was higher among the voters than partisans as a whole, the share of respondents who follow government “most of the time” still dropped 15 percent among both Biden and Trump voters.\n\n\n\nPolitical news interest by presidential vote\n\n\nNotably, the share of those who say they follow government and public affairs “most of the time” rises through the late fall of 2020 among voters from both parties, a trend that is not visible when subsetting by party identification instead of presidential vote choice. But both Biden voters and Trump voters see significant declines of 15 percent in the share of respondents who follow the news most closely between January and May of 2021.\nAnother approach to investigate whether the drop in news interest differs by political engagement is to examine how strong and weak partisans differ in their news consumption patterns. Strong partisans might be expected to maintain higher engagement regardless of who is in power, while weak partisans could be more susceptible to administration-driven changes in interest.\n\n\n\nPolitical news interest by partisan strength\n\n\nThe data shows that both strong and weak partisans experienced similar declines in high-level news engagement after January 2021. Strong partisans, who maintained consistently higher rates of following politics “most of the time” throughout the period, still saw their engagement drop from around 55-60 percent to 45-50 percent. Weak partisans experienced a parallel decline from roughly 35 percent to 30 percent.\n\n\nNews source consumption patterns mirror overall engagement trends\nBeyond general political interest, the survey also tracked specific news source consumption, asking respondents whether they got news from various outlets in the past week. The results show broad declines across multiple news sources after January 2021.\n\n\n\nNews source consumption over time\n\n\nLocal news consumption shows the steepest decline, falling from around 60 percent in early 2020 to below 50 percent by early 2021, and continuing to decline through May. Cable news networks (CNN, Fox News, MSNBC) all experienced similar patterns, with viewership peaking during the election period and dropping significantly after inauguration. Even social media news consumption through Facebook declined notably.\nWhen broken down by partisan strength, the patterns remain consistent across both strong and weak partisans, suggesting that the decline in news source consumption is not primarily driven by partisan disengagement.\n\n\n\nNews source consumption by partisan strength\n\n\nSimilarly, examining news consumption by party identification and presidential vote choice reveals parallel declines across different political groups, reinforcing the finding that this trend transcends partisan divides.\n\n\n\nNews source consumption by party identification\n\n\n\n\n\nNews source consumption by presidential vote\n\n\n\n\nConclusion\nThe evidence strongly suggests that the decline in political news interest during the first half of 2021 was not primarily driven by partisan reactions to the Biden administration. Instead, the data points to a broader, non-partisan phenomenon affecting Americans across the political spectrum.\nSeveral key findings support this conclusion. The 15 percent decline in high-level political engagement was remarkably consistent across party lines, voter preferences, and levels of partisan strength. Republicans and Democrats, Biden voters and Trump voters, strong partisans and weak partisans all experienced similar drops in their likelihood to follow politics “most of the time.” This consistency suggests a common cause rather than partisan-specific reactions.\nThe timing also supports a pandemic-related explanation. The decline began precisely as COVID-19 cases were falling and vaccine distribution was accelerating, reducing the urgency that had driven news consumption throughout 2020. The pandemic had created an environment where staying informed about government actions felt critically important for personal safety and decision-making. As that immediate threat receded, so did the intense need to follow political developments.\nAdditionally, the 2020 election cycle had created an unusually high-engagement period that was unlikely to be sustainable. The combination of a contentious presidential election, a global pandemic, and significant social unrest had elevated political news consumption to extraordinary levels. Some decline from this peak was probably inevitable regardless of which candidate won the presidency.\nThis analysis suggests that commentators may have been too quick to attribute declining news interest to Biden-specific factors. While presidential administrations certainly influence the political news environment, the data indicates that broader contextual factors—particularly the winding down of the pandemic emergency—played a more significant role in the 2021 decline in political engagement than partisan reactions to the change in administration.\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2021,\n  author = {Lorico Hertz, Zachary},\n  title = {Tracking the {Drop} in {News} {Interest}},\n  date = {2021-07-13},\n  url = {https://zacharylhertz.github.io/posts/2021-07-13-news-interest/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2021. “Tracking the Drop in News\nInterest.” July 13, 2021. https://zacharylhertz.github.io/posts/2021-07-13-news-interest/."
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "Use the filters on the right to browse my research by topic. If you’d prefer, you can download my CV in .pdf format here. You can also follow me on Google Scholar."
  },
  {
    "objectID": "research/index.html#published-papers",
    "href": "research/index.html#published-papers",
    "title": "Research",
    "section": "Published Papers",
    "text": "Published Papers\n\n\n\n\n\n  \n    \n      Does a Switch to By-District Elections Reduce Racial Turnout Disparities in Local Elections? The Impact of the California Voting Rights Act \n      \n      \n      \n      \n      \n      \n      \n        \n          2023. Zachary Lorico Hertz. Election Law Journal.\n        \n      \n      \n      \n      \n        \n          Abstract (click to expand)\n          \n            \n              The literature finds that an underrepresented group's comparative share of the population may moderate the effects of the California Voting Rights Act of 2001 on descriptive representation. Little attention has been devoted to the potential mechanisms driving these effects. Previous research suggests that electoral influence, conceptualized as an underrepresented group's relative size in a given political unit, can lead to an increase in turnout and subsequent descriptive representation. This article leverages ecological inference with nearest-neighbor matching and difference-in-differences methods to determine whether increased electoral influence following a switch from at-large to by-district elections as a result of the CVRA increased turnout among underrepresented groups. In my analysis, I find initial evidence suggesting that there is indeed a causal link between a CVRA-induced change in electoral institution and a reduction in the turnout gap. I do not find evidence to support my hypothesis that an increase in relative group size leads to a decrease in the turnout gap. I also do not find evidence to support my hypothesis that the effects of a switch to by-district elections on the turnout gap are more pronounced in cities where a minority group is a higher than average share of the total population. Instead, I find evidence that the treatment effects are more pronounced in cities where Hispanics are a lower than average share of the total population. In this work, I evaluate how the CVRA affects local California electorates, explain potential explanations for my findings and discuss potential areas for future research.\n            \n          \n        \n      \n\n      \n      \n      \n      \n      \n        \n            PDF \n        \n       \n      \n      \n      \n      \n        \n            Publisher's Version \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research",
    "section": "Working Papers",
    "text": "Working Papers\n\n\n\n\n\n  \n    \n      Noli nos tangere: Have Anti-Asian Hate Crimes Increased Asian-American Pan-Ethnicity, Participation, and Partisanship? \n      \n      \n      \n      \n        \n          May 15, 2025. Zachary Lorico Hertz. Working paper.\n        \n      \n      \n      \n      \n      \n      \n      \n        \n          Abstract (click to expand)\n          \n            \n              Hate crimes against Asian Americans in the United States spiked over 300 percent between 2020 and 2021. How might this troubling trend affect political participation and attitudes? Previous research finds that out-group threats might increase the salience of group-based identities and consequently shape political attitudes, group cohesion, and behavior (Huddy 2013), but reach mixed conclusions on whether these events are politically mobilizing or demobilizing. To investigate, I pair data encoding the geographic placement of hate crimes from 2010-2022 with individual-level turnout data to causally identify whether local hate crimes increased turnout among Asian Americans. To test potential mechanisms, I design an original survey experiment to estimate how the increased salience of hate crimes affects measures of Asian pan-ethnicity, stated vote likelihood, partisan identity and strength, and other behavioral outcomes. I find that hate crimes can strengthen group cohesion among the targeted group, but limited evidence that hate crimes have politically mobilized the targeted group and null effects on partisanship. I conclude that identity is a more complex motivator of partisanship and American electoral politics than previous studies might suggest.\n            \n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Can Ending At-Large Elections Encourage Racial Minorities To Run For Office? \n      \n      \n      \n      \n        \n          May 10, 2025. Zachary Lorico Hertz. Working paper.\n        \n      \n      \n      \n      \n      \n      \n      \n        \n          Abstract (click to expand)\n          \n            \n              Why do racial minorities remain underrepresented among office-holders, particularly at the local level? Previous research on descriptive representation focuses on voter choices at the ballot box and attributes the paucity of minority candidates to voter bias. At the same time, given findings that at-large elections can diminish racial minorities' political power and candidates selectively run in favorable political landscapes, institutional electoral rules might contribute to the persistent disparity in racial representation among candidates. Despite these expectations, the dynamics under which electoral institutions shape candidate emergence among racial minorities remains understudied. I utilize the switch from at-large to by-district city council elections under the California Voting Rights Act of 2001 to causally identify how and under what conditions switching to by-district elections encourages racial minorities to run for local office. The evidence suggests that ending at-large elections under the CVRA increased both the number and percent share of Latino candidates among city council candidates, and boosted the rates at which Latino candidates won city council elections. These effects are strongest in cities where Latinos are more than 20 percent of the population. I also find evidence to suggest that ending at-large elections increased candidate emergence among Asian Americans in cities where Asian Americans are more than 50 percent of the citywide population. These findings highlight the importance of candidate emergence as a crucial mechanism driving descriptive representation and suggest policy interventions targeting candidate recruitment might be as important as those addressing voter participation.\n            \n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Local Diversity and Political Participation \n      \n      \n      \n      \n        \n          May 5, 2025. Marco Mendoza Aviña and Zachary Lorico Hertz. Working paper.\n        \n      \n      \n      \n      \n      \n      \n      \n        \n          Abstract (click to expand)\n          \n            \n              Previous research finds that racial heterogeneity impacts a variety of outcomes, including participation. However, this relationship is complex and might be contingent on individual factors. This paper examines how the racial makeup of a locality influences political involvement among its residents. It pairs U.S. Census population estimates with validated voting records from the Congressional Elections Study for a quarter of a million citizens and a decade of federal elections. Racial diversity at the local level conditionally affects voters, fostering political engagement among Democrats but inhibiting it among Republicans.\n            \n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n    \n      Followers or Learners? Untangling the Roles of Partisanship and Reasoning in Public Policy Preferences \n      \n      \n      \n      \n        \n          Jun 10, 2022. Zachary Lorico Hertz. Working paper.\n        \n      \n      \n      \n      \n      \n      \n      \n        \n          Abstract (click to expand)\n          \n            \n              Do people thoughtlessly support positions taken by their party leaders, or carefully alter their beliefs when given reason to do so? Many studies examine the effects of cues from party leaders on policy preferences and cast voters as party loyalists, but rarely compare information from party leaders to information from other political and nonpartisan sources and thus cannot disentangle whether people rationally update their preferences or blindly follow party leaders. To investigate, I vary cues to identify the comparative strength of party leader cues and test issue importance and previous knowledge as potential moderators. I find that when asked to support or oppose a discrete policy, partisans respond to cues from party leaders but not other cues. When respondents respond with a continuous range of policy preferences, however, party leader cues are not inherently stronger — and are sometimes weaker — than cues from other sources. I find limited evidence to suggest either issue importance or political knowledge significantly moderates partisan sensitivity to elite cues, no matter the source. These results suggest that while party leaders draw partisans to express support for individual policy planks, leaders’ influence on underlying beliefs is far more complicated and voters engage in more cognition than previously suggested.\n            \n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n\nNo matching items\n\n\n\n1"
  },
  {
    "objectID": "research/index.html#footnotes",
    "href": "research/index.html#footnotes",
    "title": "Research",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThanks to Carlisle Rainey for making a template for research pages publicly available, which I have lightly tweaked to make my own.↩︎"
  },
  {
    "objectID": "lyrics/index.html",
    "href": "lyrics/index.html",
    "title": "Zachary Lorico Hertz",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 700\n\n## file: app.R\n# Big Thief Lyric Bot\n\nlibrary(shiny)\nlibrary(shinythemes)\nlibrary(dplyr)\n\n# UI\nui &lt;- fluidPage(\n  theme = shinytheme(\"flatly\"),\n  \n  tags$head(\n    tags$style(HTML(\"\n      .main-container {\n        max-width: 600px;\n        margin: 20px auto;\n        text-align: center;\n      }\n      \n      .lyrics-display {\n        background: #f8f9fa;\n        border-left: 4px solid #007bff;\n        padding: 30px;\n        margin: 30px 0;\n        border-radius: 8px;\n        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n      }\n      \n      .lyrics-text {\n        font-size: 18px;\n        line-height: 1.6;\n        color: #2c3e50;\n        font-style: italic;\n        white-space: pre-line;\n        margin-bottom: 20px;\n      }\n      \n      .attribution {\n        font-size: 14px;\n        color: #6c757d;\n        font-weight: 500;\n      }\n      \n      .btn-generate {\n        font-size: 16px;\n        padding: 12px 30px;\n        margin: 20px 0;\n        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n        border: none;\n        border-radius: 25px;\n        color: white;\n        transition: all 0.3s ease;\n      }\n      \n      .btn-generate:hover {\n        transform: translateY(-2px);\n        box-shadow: 0 5px 15px rgba(0,0,0,0.2);\n        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);\n      }\n      \n      .stats {\n        font-size: 12px;\n        color: #868e96;\n        margin-top: 20px;\n      }\n      \n      .loading {\n        color: #6c757d;\n        font-style: italic;\n      }\n    \"))\n  ),\n  \n  div(class = \"main-container\",\n    h1(\"Random Excerpt Generator\"),\n    p(\"This is a webapp I coded. I created a list of meaningful or striking excerpts from songs I've listened to, poems I like, and books I recently read.\"),\n    \n    actionButton(\"generate\", \"✨ View Random Excerpts\", class = \"btn btn-generate\"),\n    \n    uiOutput(\"lyrics_display\"),\n    \n    div(class = \"stats\",\n      textOutput(\"stats_text\")\n    )\n  )\n)\n\n# Server\nserver &lt;- function(input, output, session) {\n  # Reactive value to store the loaded data\n  lyric_chunks &lt;- reactiveVal(NULL)\n  data_loaded &lt;- reactiveVal(FALSE)\n  \n  # Load data when app starts\n  observe({\n    tryCatch({\n      data_url &lt;- \"https://zacharylhertz.github.io/files/chunks.csv\"\n      temp_file &lt;- tempfile(fileext = \".csv\")\n      download.file(data_url, temp_file, mode = \"wb\")\n      chunks_data &lt;- read.csv(temp_file, stringsAsFactors = FALSE)\n      lyric_chunks(chunks_data)\n      data_loaded(TRUE)\n      unlink(temp_file)\n    }, error = function(e) {\n      showNotification(\"Failed to load lyric data. Please check your internet connection.\",\n                       type = \"error\", duration = 5)\n    })\n  })\n  \n  # Random lyric function - now uses reactive data\n  get_random_lyric &lt;- function() {\n    chunks_data &lt;- lyric_chunks()\n    if (is.null(chunks_data) || nrow(chunks_data) == 0) {\n      return(list(\n        lyrics = \"Unable to load lyrics data\",\n        attribution = \"Please refresh the page\",\n        media = \"song\"\n      ))\n    }\n    \n    sample_chunk &lt;- chunks_data %&gt;% slice_sample(n = 1)\n    lyrics_text &lt;- sample_chunk$lyrics_chunk\n    \n    # Create title with hyperlink if URL exists and is non-empty\n    if (!is.null(sample_chunk$url) && !is.na(sample_chunk$url) && sample_chunk$url != \"\") {\n      title_html &lt;- paste0('&lt;a href=\"', sample_chunk$url, '\" target=\"_blank\" style=\"color: inherit; text-decoration: underline;\"&gt;',\n                            sample_chunk$title, '&lt;/a&gt;')\n    } else {\n      title_html &lt;- sample_chunk$title\n    }\n    \n    attribution &lt;- paste0(\"— \", title_html, \" by \", sample_chunk$artist, \" (\", sample_chunk$year, \")\")\n    \n    # Get media type, defaulting to \"song\" if column doesn't exist or is NA\n    media_type &lt;- if (\"media\" %in% names(chunks_data) && !is.na(sample_chunk$media)) {\n      sample_chunk$media\n    } else {\n      \"song\"\n    }\n    \n    return(list(lyrics = lyrics_text, attribution = attribution, media = media_type))\n  }\n  \n  # Reactive values to store current lyrics\n  current_lyrics &lt;- reactiveVal(\"Click the button above to start excerpts.\")\n  current_attribution &lt;- reactiveVal(\"— Ready to explore penmanship I appreciated?\")\n  \n  # Update when button is clicked\n  observeEvent(input$generate, {\n    if (data_loaded()) {\n      result &lt;- get_random_lyric()\n      \n      # Choose emoji based on media type\n      if (result$media == \"song\") {\n        current_lyrics(paste(\"🎵\", result$lyrics, \"🎵\"))\n      } else {\n        current_lyrics(paste(\"📝\", result$lyrics, \"📝\"))\n      }\n      \n      current_attribution(result$attribution)\n    } else {\n      showNotification(\"Data is still loading, please wait...\", type = \"warning\")\n    }\n  })\n  \n  # Render the lyrics display\n  output$lyrics_display &lt;- renderUI({\n    div(class = \"lyrics-display\",\n      div(id = \"lyrics-output\",\n        div(class = \"lyrics-text\", current_lyrics()),\n        div(class = \"attribution\", HTML(current_attribution()))\n      )\n    )\n  })\n  \n  # Stats text\n  output$stats_text &lt;- renderText({\n    if (data_loaded() && !is.null(lyric_chunks())) {\n      paste(\"Built from\", nrow(lyric_chunks()), \"lyrical or literary excerpts.\")\n    } else {\n      \"Loading lyric data...\"\n    }\n  })\n}\n\n# Create the app\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/2024-11-05-black-nonvoters/index.html",
    "href": "posts/2024-11-05-black-nonvoters/index.html",
    "title": "What Can Survey Data Tell Us About Ideological Differences Between Black Voters and Black Nonvoters?",
    "section": "",
    "text": "I’ve made the replication code for this blog post publically available, here as a GitHub repository.\nAnalysts love the truism that elections can be seen through two lenses: persuasion and turnout. And today, as voting ends for an election that will likely be decided by a margin of a few hundred thousand voters across seven states, particular attention has been brought to the latter. A recent Good Authority piece makes the crucial point1 that Black voters are called upon to either save the day or serve as scapegoats depending on the election results, and analysis that treats Black Americans as a monolithic voting bloc misses important dynamics in the race.\nThe Good Authority piece seems, in part, to be a response to the plethora of pre-election pieces that focus on low-turnout Black voters. In particular, Nate Cohn of the New York Times has written several pieces suggesting that Black voters who did not vote in 2020 will be crucial in determining this year’s results. He’s not the only one: similar pieces ran in CNN and Time, and these claims have been made by pundits and academics alike. Yet while much ink has been spilled ahead of today’s election trying to estimate how the 2024 election might be shaped by winning over the group of Black voters who sat out 2020, very few analysts writing about Black Americans have focused on how 2020 voters and non-voters differ. Additionally, to the extent that these pieces have considered possible differences, their ability to establish definitive findings are largely limited because they are drawn from pre-election polling of relatively small subgroups, meaning large margins of error can obscure real differences.\nHow do Black Americans who chose to vote in 2020 differ from those who sat out the election? What policy areas might motivate those who sat out in 2020 to vote in 2024, and how do their attitudes on racial and gender issues differ? To answer these questions, I use the 2020 Cooperative Election Study, which presents two distinctive advantages over analysis relying on pre-election polling. The large sample size of the CES reduces the margin of error when estimating differences between Black Americans who voted in 2020 and Black Americans who stayed home in 2020 (the 2020 data has n=3,096 Black voters and n=1,816 Black non-voters); additionally, CES respondents reply to a large battery of attitudinal and policy questions, allowing me to assess differences in opinion across a wide number of potential issues. Voter status is determined using the CL_2020gvm variable: respondents with a validated voting record, no matter their mode of participation, are defined as voters. Both matched non-voters and non-matched respondents are defined as non-voters; a deeper discussion of this definition can be found in the CES Guide."
  },
  {
    "objectID": "posts/2024-11-05-black-nonvoters/index.html#footnotes",
    "href": "posts/2024-11-05-black-nonvoters/index.html#footnotes",
    "title": "What Can Survey Data Tell Us About Ideological Differences Between Black Voters and Black Nonvoters?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI highly recommend reading the piece — by Nadia E. Brown, Christopher J. Clark, Anna M. Mahoney, Periloux Peay, and Michael G. Strawbridge — in its entirety. Plus, don’t you need something to keep your mind off drawing overly strong conclusions from early returns?↩︎"
  },
  {
    "objectID": "posts/2021-08-05-youth-turnout/index.html",
    "href": "posts/2021-08-05-youth-turnout/index.html",
    "title": "Estimates of Youth Turnout Have Recently Diverged",
    "section": "",
    "text": "With the recent release of the final 2020 Cooperative Election Study (CES) dataset, which includes vote validation, I returned to an earlier project examining youth voter turnout. In looking at voter turnout among adults under the age of 30, I noticed a pronounced gap between estimates from the Center for Information & Research on Civic Learning and Engagement (CIRCLE) and the CES.\n\nCES and CIRCLE estimates of youth voter turnout have been fairly close, but differed by 12 percentage points in 2020\nThere are three different ways to measure turnout using the vote validation variables in the CES. I calculated CES estimates of voter turnout using the first method, coding the unmatched as non-voters. I collected CIRCLE estimates of youth voter turnout for 2020 and 2016, 2018, 2014, 2012, and 2010 from press releases. I then calculated the absolute value of the difference between the CES and CIRCLE estimates, then plotted the results.\n\nWe see that the 2010 and 2012 youth voter turnout estimates were incredibly close, with a difference of just 0.2 and 0.1 percentage points respectively. These differences widened slightly between 2014 and 2018 but remained within about 3 percentage points: estimates differed by 3.3 percentage points in 2014, 1.0 percentage points in 2016, and 2.6 percentage points in 2018. In 2020, however, while the CES validated vote data estimated that voter turnout among adults ages 18-29 was 38 percent, CIRCLE found that 50 percent of adults between 18 and 29 turned out to vote, marking a difference of 12 percentage points.\n\n\nPotential causes\nThe 12-point difference in the CIRCLE and CES estimates of youth voter turnout may be the result of methodological differences. CIRCLE states that their estimates are based on voter file data from 41 states — Alaska, DC, Hawaii, Maryland, Mississippi, New Hampshire, North Dakota, Utah, Wisconsin, and Wyoming lack reliable vote history data by age. These states are not omitted from the CES data, however, so unobserved youth voting behavior in the 10 omitted states could lead to different estimates from the different sampling frame.\nThe CES data guide also notes vote validation matches are only made when there is a high level of confidence that respondents are assigned to the correct record. Therefore, CES records may lack vote validation due to incomplete or inaccurate information. It is also possible that there may be a systemic issue with incomplete or inaccurate voter file data, particularly among those under the age of 30.\n\n\n\n\nCitationBibTeX citation:@online{lorico_hertz2021,\n  author = {Lorico Hertz, Zachary},\n  title = {Estimates of {Youth} {Turnout} {Have} {Recently} {Diverged}},\n  date = {2021-08-06},\n  url = {https://zacharylhertz.github.io/posts/2021-08-05-youth-turnout/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLorico Hertz, Zachary. 2021. “Estimates of Youth Turnout Have\nRecently Diverged.” August 6, 2021. https://zacharylhertz.github.io/posts/2021-08-05-youth-turnout/."
  },
  {
    "objectID": "posts/2025-08-15-winners-and-lousers/index.html",
    "href": "posts/2025-08-15-winners-and-lousers/index.html",
    "title": "In WAR, There Are No Winners But All Are Lou-sers",
    "section": "",
    "text": "I’ve made the replication code for this blog post publically available, here as a GitHub repository.\nSpeaker emerita Nancy Pelosi recently made headlines when she was spotted visiting fellow Italian-American Stefanie Germanotta at the Mayhem Ball in San Francisco earlier this month. “It was a fabulous show in San Francisco,” Pelosi wrote from her official account in a quote tweet of Pop Crave. “The most fun I’ve had in a long time.”\nAnd, to be sure, it seems from the outside that for Pelosi there’s been a shortage of fun to be had recently after November’s elections swept Donald Trump back into the White House and Republicans into majorities in both chambers of Congress. Pelosi herself had an unremarkable November on paper, winning 81 percent of the vote and cruising to victory over her Republican challenger Bruce Lou.\nBut the headline commanding margin belies some interesting quirks to this particular victory. First, Lou’s seemingly paltry 19 percent still marked the highest vote share of any Republican challenger Pelosi has faced since 1990.1 This suggests that despite losing in a blowout, perhaps Lou managed to find appeal that previous challengers to Pelosi failed to muster.\nSecond, a lot of ink has been recently spilled in the WAR2 wars. Split Ticket’s 2024 House WAR metrics suggested that the WAR in CA-11 was a whopping R+10.6, suggesting that Lou ran 10.6 points above a “replacement” Republican candidate. The recently-released metric from G. Elliot Morris and Mark Rieke claims instead that Pelosi’s WAR was +4, suggesting that actually her performance was slightly better than what we would expect from a replacement Democrat. Say what you will about WAR metrics (for example, that they are highly sensitive to researcher specification and struggle to attribute results correctly to one candidate’s overperformance versus their opponent’s underperformance) but clearly these approaches still are inconclusive. Considering the district directly and in context provides a way to adjudicate between these competing findings.\nThird, others have noted3 that San Francisco saw strong shifts towards Republicans in Asian neighborhoods but have failed to put the trend into context. Considering the historical context, down-ballot performance, trends, and neighborhood-level diversity adds to this analysis.\nFourth, and perhaps most importantly in motivating me to actually write this piece up, I actually know Lou from our time playing quiz bowl in high school.4 So, with these points in mind, I wrote up a short post to answer a few questions. Was Lou’s (relatively) strong performance buoyed by a particular ability to leverage appeals to the Asian community, or did his loss simply mark a continuation of declining support for an aging Pelosi?"
  },
  {
    "objectID": "posts/2025-08-15-winners-and-lousers/index.html#extra-maps",
    "href": "posts/2025-08-15-winners-and-lousers/index.html#extra-maps",
    "title": "In WAR, There Are No Winners But All Are Lou-sers",
    "section": "Extra Maps",
    "text": "Extra Maps\n\n\n\nNeighborhoods of San Francisco, as defined by the city planning department. Click to expand.\n\n\nAs a treat, I’ve left this interactive map of the general results for you to look through."
  },
  {
    "objectID": "posts/2025-08-15-winners-and-lousers/index.html#data-sources",
    "href": "posts/2025-08-15-winners-and-lousers/index.html#data-sources",
    "title": "In WAR, There Are No Winners But All Are Lou-sers",
    "section": "Data Sources",
    "text": "Data Sources\n\nElection Data\nShapefiles\nCD boundaries\nSteven Manson, Jonathan Schroeder, David Van Riper, Katherine Knowles, Tracy Kugler, Finn Roberts, and Steven Ruggles. IPUMS National Historical Geographic Information System: Version 19.0 [dataset]. Minneapolis, MN: IPUMS. 2024. http://doi.org/10.18128/D050.V19.0"
  },
  {
    "objectID": "posts/2021-12-16-party-cues/index.html",
    "href": "posts/2021-12-16-party-cues/index.html",
    "title": "How Sensitive are Partisans to Out-Party Cues?",
    "section": "",
    "text": "A recent working paper by Anthony Fowler and William Howell finds that partisans update their policy beliefs in response to both in- and out-party elite cues. I found the paper especially notable for a few reasons: its findings are well-supported yet somewhat incongrous with both previous research and the oft-cited1 expression that “partisanship is a hell of a drug”.2 Given the paper’s novelty and relevance to my own research interests, I ran an extension and replication in May 2021. Do partisans update their policy beliefs in response to elite cues from both in-party and out-party leaders?\nI follow the methods outlined by Fowler and Howell to design four survey experiments. The first is a replication of the authors’ experiments on the federal minimum wage, while the other two extend their design to examine policy preferences for spending on national security and a hypothetical infrastructure bill."
  },
  {
    "objectID": "posts/2021-12-16-party-cues/index.html#footnotes",
    "href": "posts/2021-12-16-party-cues/index.html#footnotes",
    "title": "How Sensitive are Partisans to Out-Party Cues?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee, for example, its frequent use by political scientists on Twitter.↩︎\nOne which seems to have been created and popularized by Brendan Nyhan and Stephen Miller.↩︎\nThe infrastructure bill had no status-quo equivalent, so respondents were simply presented with the sentence: “Congress is currently considering an infrastructure bill to create jobs and rebuild national infrastructure.”↩︎\nWhile the analysis of pooled partisans excluding leaners is omitted for brevity, doing so actually strengthens the treatment effects slightly to 0.25 for both in-party and out-party positions in the minimum wage experiment.↩︎\n[Photo by Kelly Sikkema on Unsplash.]↩︎"
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "",
    "text": "At various points in this class, we will ask you to complete proofs as part of your assessments. Proofs may be unfamiliar to many of you1, particularly since they are not taught in math camp, so I want to give you some advice on how to approach proofs.\n1 If you’ve managed to avoid learning about proofs to this point, I’ll note very quickly that a mathematical proof is a specific kind of deductive argument structured to derive some arbitrary mathematical statement, in which the analyst uses the premises and mathematics to show that the conclusion is logically guaranteed by the premises.The zeroth step in solving proofs is to identify when you are being asked to write one. We will usually not literally state “write a proof showing \\(x\\).” Instead, you’ll see the words “Show that…” or “Prove that…”, sometimes following a premise. When you see these in your problem set questions, you’ll know it’s time to lock in and write a proof.\nBefore we get too far into this guide, I also want to caution that proofs are, unfortunately, more of an art than a science. This is unfortunate because a lack of hard and fast rules or a clear “how-to” is at odds with the student’s impulse to be told how to do something. I struggled with them when I was first learning math for this reason, but this document serves as a synthesis of the advice I’ve found that was helpful, and my attempt to satisfy that impulse.\nI’ll note that it can also help to think of the proof writing process as similar to solving a maze or puzzle: you have a set starting point and a set end point, but it’s up to you to figure out the correct set of actions that will actually get you there. At many points in the proof you will have to make a decision about what to do next, and it might not be the right one! But, like solving a maze, you can always undo steps to try and feel your way to the solution. Furthermore, because each proof is different, ultimately the best way to improve is practice."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-0-what-is-the-question-asking-me",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-0-what-is-the-question-asking-me",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 0: What is the question asking me?",
    "text": "Step 0: What is the question asking me?\nThis step sounds trivial, but don’t fall into the trap of skipping it. This can be deceptively tricky! Getting a handle on what is being asked of you, both in the literal question and the larger didactic point it is trying to make, will go a long ways towards finding a solution. Consider connections between the question and the specific examples from lecture or section; draw it out if you need to. If you can get a solid understanding on this point, the solution may fall into place."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-1-define-the-beginning-and-the-end.",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-1-define-the-beginning-and-the-end.",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 1: Define the beginning and the end.",
    "text": "Step 1: Define the beginning and the end.\nWith any proof, there is some statement that we are being asked to prove. When you have not yet written the proof, the statement is called a conjecture; once it has been shown to be true it is a theorem. Within that statement you have some information that you are given as fact, called the premise (or, sometimes, the hypothesis), as well as the thing that you are ultimately trying to prove, called the conclusion. So, make sure when reading to look at the problem closely.\nYour premise is usually identified with some key words: let, suppose, if, assume, consider, say, given are all examples. This information is treated as an underlying assumption; in fact, treating the premise as a simple and true fact of the world will be crucial to completing your proof. This is your starting point; it might even help to highlight this.\nYour conclusion is also identified with key words: implies, show, then, prove all are possible words indicating a conclusion. Use these to identify the statement that you need to reach by manipulating your hypotheses and applying definitions. The conclusion is where we need to end the proof; again, I might even highlight the conclusion to make it easier to return to on the paper.\nYou must start your proof with an initial statement of what you are trying to prove. For example, some question might say that “There is some \\(x, y \\in \\mathbb{R}\\). Show that \\(x&gt;5\\) implies \\(x^2 &gt;25\\).” We notice the premise is \\(x \\in \\mathbb{R}\\), since that is the information given as a premise ahead of our conclusion. We also spot our conclusion coming around the word implies: the full conclusion is \\(x&gt;5\\) implies \\(x^2 &gt;25\\). To start your proof, we might start by rephrasing the conclusion: “If \\(x&gt;5\\), then \\(x^2 &gt;25\\).”\nWe always start by restating the conclusion because doing so forces you to ask yourself “What am I trying to prove?”. This will serve as a sort of common thread4 to which we can return throughout the proof.\n4 In the metaphorical Ariadnian sense, though not the formal one."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-2-define-your-terms.",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-2-define-your-terms.",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 2: Define your terms.",
    "text": "Step 2: Define your terms.\nThis is good general advice, but a critical step in proofing.5 The first time you introduce any variable, whether in the initial statement, the proof itself, or the conclusion, you must state a definition for the variable.\n5 I’m pretty sure this is not an acceptable verb form to describe this process, and instead exclusively refers to the baking technique. But we have to have fun sometimes.This will also be helpful for solving the proof. Often, mathematics relies on the use of definitions themselves as tools to gain leverage on the proof. For example, if we know that if a random variable \\(X\\) that has a CDF \\(F(x)\\), it is definitionally true that the probability \\(X\\) exceeds some value \\(x\\) \\(\\mathbb{P}(X\\geq x)\\) is equal to \\(1-F(x)\\). If, at some point, we have a statement about the probability \\(\\mathbb{P}(X\\geq x)\\), we could then swap it with \\(1-F(x)\\) because of this definition. So, we can see that definitions will sometimes get us out of a tight spot."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-3-begin-writing-in-steps.",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-3-begin-writing-in-steps.",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 3: Begin writing in steps.",
    "text": "Step 3: Begin writing in steps.\nYou want to write proofs in a natural, step-by-step order, like a manual or (at risk of mixing my metaphors) a recipe. As we’ve stated before, you must begin by stating the assumptions given by the problem and then following a logical set of steps from that point to reach the conclusion. The reason (against future best practice) it will help you to write out each step clearly and explicitly, even if they seem obvious, is that it helps readers (including your future self) follow the steps closely with less effort."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-4",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-4",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 4: ?????",
    "text": "Step 4: ?????\nFrom here, there are a number of strategies you might take to complete your proof. This depends whether you are choosing to prove your conclusion is true or whether you are choosing to prove the conclusion is false.\nIf you are trying to prove your conclusion is true, there are three common strategies: direct proofs (which are generally preferred), proofs by contrapositive, and proof by contradiction.\n\nFor a true conclusion: Direct proofs\nPerhaps the thing you are trying to prove can be distilled into a simple form: “If \\(P\\), then \\(Q\\).” One classic example is the proof “If \\(n\\) is an even integer, then \\(n^2\\) is even,” but a wide variety of statements for potential direct proofs exist: consider “If \\(\\mathbb{P}(A)=1\\), then \\(\\mathbb{P}(A \\cup B )=1\\)” or “If \\(a \\succsim b\\) and \\(b \\succsim c\\), then \\(a \\succsim c\\).”\nComposing a direct proof is mechanically simple in abstract terms. Because we are trying to prove the conditional statement “If \\(P\\), then \\(Q\\),” we start by assuming that \\(P\\) is true (our premise!), then set up some implication \\(P_1\\) that follows from \\(P\\). Then, having gotten to \\(P_1\\), we find some implication \\(P_2\\) that follows from \\(P_2\\). We do this until we arrive at some \\(P_n\\), for which if \\(P_n\\) is true, it follows that \\(Q\\) is true.\nThis is perhaps more clear with a direct example. Consider again the statement “If \\(n\\) is an odd integer, then \\(n^2\\) is odd,” which I shall prove with a direct proof.\nConjecture: If \\(n\\) is an odd integer, then \\(n^2\\) is odd.\nProof: Since \\(n\\) is odd (given by the premise), by the definition of odd integers there must exist some integer \\(k\\) such that \\(n=2k+1\\). If \\(n=2k+1\\), then \\(n^2 = (2k+1)^2\\). Then:\n\\[\\begin{align*}\nn^2 &= (2k+1)^2 \\tag{from above} \\\\\n&= 4k^2 + 4k + 1 \\tag{$(a+b)^2 = a^2 + 2ab + b^2$} \\\\\n&= 2(2k^2 + 2k) + 1 \\tag{arithmetic}\n\\end{align*}\\]\nIn our last step, we found a way to re-express \\(n^2\\) in the form \\(2 \\times (\\text{some integer}) + 1\\), which is the definition of odd integers. Therefore, for an odd integer \\(n\\), \\(n^2\\) is odd.\n\n\nFor a true conclusion: Proofs by contrapositive\nWhile statements of the form “If \\(P\\), then \\(Q\\)” can usually be solved by direct proof, sometimes we need to rely on other approaches. One fact we can exploit is the fact that “If \\(P\\), then \\(Q\\)” is logically equivalent to the statement “If not \\(Q\\), then not \\(P\\),”6 which we call the contrapositive. So, sometimes, rather than doing a direct proof of “If \\(P\\), then \\(Q\\)” we can rely on a proof instead of “If not \\(Q\\), then not \\(P\\).” This is called proof by contraposition.\n6 But, importantly, this is not equivalent to the statement “If not \\(P\\), then not \\(Q\\).”To follow the intuition here, consider a statement “If I am at the Big Thief concert, then I bought a ticket;” hopefully you can see that this is a statement with the form “If \\(P\\), then \\(Q\\)” where \\(P\\) is “I am at the Big Thief concert” and \\(Q\\) is “I bought a ticket (for that concert).” Our original statement is logically equivalent to the contrapositive statement “If I did not buy a ticket, I am not at the Big Thief concert.” So, of course, if we can prove the statement “If I did not buy a ticket, I am not at the Big Thief concert” is true, we will have necessarily also proved the statement “If I am at the Big Thief concert, then I bought a ticket.”\nAgain, I use an example to help illustrate proof by contrapositive in action. We take a related statement to our first example: “Let \\(x\\) be an integer. Prove that \\(x^2\\) is an odd number if and only if \\(x\\) is an odd number.” As a note, the “if and only if” in this statement requires us to prove both directions of the implication. In other words, we must first prove that if \\(x\\) is odd, then \\(x^2\\) is odd. Second, we must prove that if \\(x^2\\) is odd, then \\(x\\) is odd. We have already proven the first statement above; for the second statement, we use proof by contrapositive.\nConjecture: Let \\(x\\) be an integer. Then \\(x^2\\) is odd if and only if \\(x\\) is odd.\nProof: The contrapositive of “if \\(x^2\\) is odd, then \\(x\\) is odd” is “if \\(x\\) is even, then \\(x^2\\) is even.” It suffices to prove this contrapositive.\nSuppose \\(x\\) is even. By the definition of even integers, there exists some integer \\(k\\) such that \\(x = 2k\\). Then:\n\\[\\begin{align*}\nx^2 &= (2k)^2 \\tag{substitution} \\\\\n&= 4k^2 \\tag{$(ax)^2 = a^2 x^2$} \\\\\n&= 2(2k^2) \\tag{arithmetic}\n\\end{align*}\\]\nSince \\(k\\) is an integer, \\(2k^2\\) is also an integer. Thus \\(x^2\\) is in the form \\(2 \\times (\\text{some integer})\\), which is the definition of even integers. Therefore, if \\(x\\) is even, then \\(x^2\\) is even, completing the proof by contrapositive.\nThis is somewhat of an awkward process, and thinking ahead I don’t believe there’s any point where you will be required to do proof by contraposition in this course.7 But, of course, it exists and others might like it, so in the spirit of keeping this a thorough discussion of proof strategies I included it anyways.\n7 As a disclaimer, I have not gone ahead in the course materials, so I could be wrong. Please don’t sue me!\n\nFor a true conclusion: Proof by contradiction\nInstead, in what is technically a particular type of proof by contrapositive, we can start with an assumption that the original statement is not true. If an example exists such that it is impossible that the original statement could be not true, then logically we must conclude that the original statement is true.\nEssentially, what this requires you to do is take the premise(s) in the statement, and assume that all premises are true but the conclusion itself is false. From there, use definitions and mathematics to work your way to the contradicting statement.\nOf course, I want to give you an example of proof by contradiction in action. Consider the statement “If \\(n\\) is an even perfect square with both \\(m\\) and \\(n\\) integers and \\(n = m^2\\), then \\(m\\) is even.”\nConjecture: If \\(n\\) is an even perfect square with both \\(m\\) and \\(n\\) integers and \\(n = m^2\\), then \\(m\\) is even.\nProof: Suppose \\(n\\) is even (given by the premise). We proceed by contradiction. Assume for the sake of contradiction that \\(m\\) is not even, meaning \\(m\\) is odd. By the definition of odd integers, there exists some integer \\(k\\) such that \\(m = 2k + 1\\). Then:\n\\[\\begin{align*}\nn &= m^2 \\tag{given} \\\\\n&= (2k+1)^2 \\tag{substitution} \\\\\n&= 4k^2 + 4k + 1 \\tag{$(a+b)^2 = a^2 + 2ab + b^2$} \\\\\n&= 2(2k^2 + 2k) + 1 \\tag{arithmetic}\n\\end{align*}\\]\nSince \\(k\\) is an integer, \\(2k^2 + 2k\\) is also an integer. Thus \\(n\\) is in the form \\(2 \\times (\\text{some integer}) + 1\\), which is the definition of odd integers. This means \\(n\\) is odd.\nHowever, this contradicts our premise that \\(n\\) is even. Therefore, our assumption that \\(m\\) is odd must be false, and we conclude that \\(m\\) is even. \n\n\nFor a true conclusion: Proof by induction\nAnother powerful technique is proof by induction, which is particularly useful for proving statements about natural numbers or sequences. The basic idea is like climbing a ladder: if you can get on the first rung, and you can prove that being on any rung lets you reach the next rung, then you can climb the entire ladder.\nMore formally, to prove a statement \\(P(n)\\) is true for all natural numbers \\(n \\geq n_0\\), we follow these steps:\n\nBase case: Starting with the “base case,” prove that \\(P(n_0)\\) is true (usually \\(n_0 = 0\\) or \\(n_0 = 1\\)).\nInductive hypothesis: Then, we take what is called the “inductive hypothesis,” and assume that \\(P(k)\\) is true for some arbitrary integer \\(k \\geq n_0\\).\nInductive step: Using the assumption that \\(P(k)\\) is true, prove that \\(P(k+1)\\) is also true.\n\nIf we can complete all three steps, we’ve proven the statement is true for all \\(n \\geq n_0\\).\nAs before, I include an illustrative example. Consider the statement “For all positive integers \\(n\\), the sum of the first \\(n\\) positive integers equals \\(\\frac{n(n+1)}{2}\\).” In other words, \\(1 + 2 + 3 + \\cdots + n = \\frac{n(n+1)}{2}\\).\nConjecture: For all positive integers \\(n\\), \\(\\sum_{i=1}^{n} i = \\frac{n(n+1)}{2}\\).\nProof: We proceed by induction on \\(n\\).\nBase case (\\(n=1\\)): When \\(n=1\\), the left side is simply \\(1\\). The right side is \\(\\frac{1(1+1)}{2} = \\frac{2}{2} = 1\\). Since both sides equal \\(1\\), we can conclude that the base case is true, and move on.\nInductive hypothesis: Assume that for some arbitrary positive integer \\(k\\), the statement holds. That is, assume: \\[\\sum_{i=1}^{k} i = \\frac{k(k+1)}{2}\\]\nInductive step: We must show that the statement holds for \\(k+1\\). That is, we need to prove: \\[\\sum_{i=1}^{k+1} i = \\frac{(k+1)(k+2)}{2}\\]\nStarting with the left side: \\[\\begin{align*}\n\\sum_{i=1}^{k+1} i &= \\left(\\sum_{i=1}^{k} i\\right) + (k+1) \\tag{separating the last term} \\\\\n&= \\frac{k(k+1)}{2} + (k+1) \\tag{by inductive hypothesis} \\\\\n&= \\frac{k(k+1)}{2} + \\frac{2(k+1)}{2} \\tag{common denominator} \\\\\n&= \\frac{k(k+1) + 2(k+1)}{2} \\tag{arithmetic} \\\\\n&= \\frac{(k+1)(k+2)}{2} \\tag{factoring}\n\\end{align*}\\]\nThis is exactly what we wanted to show. Therefore, by the principle of mathematical induction, the statement holds for all positive integers \\(n\\).\n\n\nFor a false conclusion: Proof by counterexample\nIf you are trying to prove your conclusion is false, we rely on proof by counterexample. Similar to proof by contradiction, all you need to do is find a single counterexample for which the statement is false! This is best done with a simple counterexample. Do not try to construct a general argument that states the statement is universally false. To restate the intuition, if we do not believe that \\(Q\\) is false, it must be true."
  },
  {
    "objectID": "posts/2026-01-29-putting-in-the-proofs/index.html#step-5-profit",
    "href": "posts/2026-01-29-putting-in-the-proofs/index.html#step-5-profit",
    "title": "Proof Advice and Strategies for Political Scientists",
    "section": "Step 5: Profit",
    "text": "Step 5: Profit\nUsing these strategies, you should be well on your way to proofing successfully. I’ll leave you with a number of miscellaneous tips and rules of thumb.\n\nFirst, to emphasize, there are many correct ways to get to the same end result. This is both why proofs are interesting, and also why they are hard.\nSecond, we (those outside of STEM, anyways) often think of math as distinct from writing. But you should treat your proofs as written content, or essays. What does that mean exactly? Recall that when we are writing proofs, our ultimate goal is to construct and elucidate a valid line of reasoning. Thus, your proofs should start with a word (or even a sentence!), and as a rule of thumb make sense when read aloud. This is why we practiced examples in our first section; now, you get to put it into practice. Proofs should be easy to read in a literal sense: use line breaks generously.\nWriting on scratch paper before typesetting in LaTeX will help you try multiple approaches when needed. I generally recommend starting on physical paper.\nIf you don’t know where to start, try writing out the assumption(s), any additional implications of these assumptions, and the definitions of the term(s) in the assumption(s) and conclusion. What more can you conclude from what’s given? What do you need to be true in order for the conclusion to hold?\nSometimes, if you get stuck, try seeing what can be done to work backwards from the conclusion. While the proof will ultimately be read linearly from start to finish, nothing says you have to work that way!\nOne tip from our friends in the math department is to inject a little art into your mathematics. Specifically, they suggest drawing a table somewhere on your scrap paper. I don’t mean something filled regressions - a literal, four-legged piece of furniture.8 Any time you add a new object to your proof, give it a one-letter name (remember, mathematicians love that) and draw it on the table. This is useful because it: a. forces you to define your objects, b. gives them names, and c. places your set of objects visually in front of you in an organized place, where you can think about how they relate to one another.\nTo paraphrase Don Draper, if you don’t like what you’re looking at, change what you’re looking at. Substituting in definitions, dividing or multiplying by \\(1\\), adding \\(0\\) can all help you get traction on your proof.\nIt’s usually better for the purposes of reaching a solution to over-write than under-write: write your thoughts, confusion, basic definitions, parallel examples, and the like. Just be sure your final draft is compact and neat.\nAvoid phrases like “clearly,” “obviously,” or “as you can see.” These phrases often indicate that you have skipped a step that is necessary for your reader, or that you’ve failed to justify a link or statement.\nStylistically, mathematical proofs avoid the singular first-person pronoun (there is no ‘I’ in math) in favor of the first-person plural. Do your best Queen Victoria: “We see that…, *We can conclude…” etc.\nAgain, every variable, letter, or piece of notation must be explicitly defined. This is useful for analytical traction, and necessary for your reader.\nFinally, signpost the ending. Make sure you reach the correct conclusion, and state that you have reached the conclusion explicitly: “Thus, we find…, We therefore prove that…” etc.\n\n8 At least, to me, though I think many (if not all) people would agree!"
  },
  {
    "objectID": "posts/2021-11-23-educational-polarization/index.html",
    "href": "posts/2021-11-23-educational-polarization/index.html",
    "title": "Educational Polarization: A White Phenomenon?",
    "section": "",
    "text": "Recently, CES Researcher Pia Deshpande wrote an excellent tutorial detailing how to plot trends over time using CES data — I highly encourage anyone who hasn’t yet read the piece to promptly do so! This style of plot pairs particularly well with the cumulative CES Common Content dataset created by Shiro Kuriwaki. Together, these resources can help us to understand an issue that has received increased attention in recent months: educational polarization.\nResearch has noted an increasing divide in party identification along educational lines. But less attention has been devoted to how these changes differ by race. Using CES data, I note that across most racial groups, Americans with a college education less strongly identify as Republicans while Americans without a college degree less strongly identify as Democrats. These trends in partisan identification are complex, however, and differ in strength and effect by race. When it comes to vote choice, however, educational polarization is mostly limited to white Americans."
  },
  {
    "objectID": "posts/2021-11-23-educational-polarization/index.html#footnotes",
    "href": "posts/2021-11-23-educational-polarization/index.html#footnotes",
    "title": "Educational Polarization: A White Phenomenon?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is worth noting that Black Americans with a college degree were the only college-educated racial group to identify as Democrats at a statistically significant lower rate in 2020 than in 2016 and 2012; this decline, however, was less pronounced than the attrition among those without a college degree so still led to a statistically significant educational gap.↩︎\nLike before, the relatively smaller sample size of Asian Americans in the CES leads to large errors for the point estimates, so it is an important caveat to note that the educational differences in 2008 and 2012 are not statistically significant. Still, following the overall trends these differences grow and by 2016 and 2020 the difference in the point estimates are statistically significant.↩︎"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Zachary Lorico Hertz",
    "section": "",
    "text": "Hey, it’s good to see you here!\nThanks for taking the time to get to know me. My name is Zachary Lorico Hertz and I am a third-year Ph.D. student at UC Berkeley. I study how identities develop, are expressed through political behavior, and intersect with power in local politics. In my research, I use causal inference methods, geocoded large-N observational data, and original survey data to study the effects an increasingly diverse and partisan electorate will have on representation and sub-national institutions. My writing has been featured in academic and popular outlets, including the Election Law Journal and the Washington Post.\nCurrently, I am the Programming and Data Manager at the Berkeley IGS Poll. Previously, I worked as an Analyst at Data for Progress, where I fielded and analyzed polling data for a number of clients in progressive politics. In addition to my academic research, I have done independent political consulting for Groundwork Project, Data for Progress, and private clients. I received an M.A. from the University of Chicago, and a B.A. from Tufts University. I also write poetry, with work forthcoming in Yearling, LEON Literary Magazine, and Eulogy Press.\nWhile much of my time is devoted to reading, writing, or coding, I enjoy hiking, quiz bowl, and both performing and producing music in my spare time. I am in a band with other Ph.D. students called Good Bones, named for the poem by Maggie Smith (no, not that one). Send me an email and let’s talk more!"
  },
  {
    "objectID": "poetry/index.html",
    "href": "poetry/index.html",
    "title": "Poetry",
    "section": "",
    "text": "I also write poetry. Some of them have even been published! You can browse those works here."
  },
  {
    "objectID": "poetry/index.html#published",
    "href": "poetry/index.html#published",
    "title": "Poetry",
    "section": "Published",
    "text": "Published\n\n\n\n\n  \n    \n      nine thousand nine hundred ninety nine days\n      \n      \n        \n        \n          LEON Literary Review. November 2025.\n        \n      \n      \n      \n        \n        \n           Read it here.\n        \n      \n      \n      \n      \n    \n  \n    \n      In my hometown\n      \n      \n        \n        \n          Eulogy Press. July 2025.\n        \n      \n      \n      \n        \n        \n           Read it here.\n        \n      \n      \n      \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "poetry/index.html#forthcoming",
    "href": "poetry/index.html#forthcoming",
    "title": "Poetry",
    "section": "Forthcoming",
    "text": "Forthcoming\n\n\n\n\n  \n    \n      For Grace, After A Wedding\n      \n      \n        \n        \n          Yearling. Expected December 2025. (after Frank O'Hara).\n        \n      \n      \n      \n      \n      \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Use the filters on the right to browse courses I have taught by topic."
  },
  {
    "objectID": "teaching/index.html#university-of-california-berkeley",
    "href": "teaching/index.html#university-of-california-berkeley",
    "title": "Teaching",
    "section": "University of California, Berkeley",
    "text": "University of California, Berkeley\n\n\n\n\n\n  \n    \n      PS232-A: Formal Models in Political Science I \n      \n      \n      \n      \n        Spring 2026. Graduate student instructor for Sean Gailmard.\n      \n      \n      \n      \n\n      \n      \n        \n          Course Description (click to expand)\n          \n            \n              This is a first course on game theory and its application in political science research. It covers elements of utility theory, representations of static and dynamic games under complete and incomplete information, and analysis of games based on Nash equilibrium and refinements. The major course objectives are to enable students to solve formal problems containing these elements, and to begin consuming scholarly literature based on them.\n            \n          \n        \n      \n\n      \n      \n        \n           Syllabus\n         \n      \n\n      \n      \n        \n           Section Syllabus\n         \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n    \n  \n    \n      PS 3: Introduction to Empirical Analysis and Quantitative Methods \n      \n      \n      \n      \n        Fall 2025. Graduate student instructor for David Broockman.\n      \n      \n      \n      \n\n      \n      \n        \n          Course Description (click to expand)\n          \n            \n              Data is increasingly central to politics, policy, law, business, and life. No matter where your life or career takes you, you will need to rely on analyzing and interpreting data -- be it understanding how persuasive a study summarized in a news article is, making a case before a judge, deciding which voters to target in your political campaign, as a political leader trying to decide what policy best serves your constituents, or as a political scientist trying to understand how politics works. The purpose of this class is to equip you to better understand how to gather and interpret data that speaks to important questions of all kinds. Much of the course, although not all of it, will focus on applications in political science, teaching you how to pose and answer political science research questions in a rigorous way.\n            \n          \n        \n      \n\n      \n      \n        \n           Syllabus\n         \n      \n\n      \n      \n        \n           Section Syllabus\n         \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n    \n  \n    \n      PS 109-B: The Politics of Public Policy \n      \n      \n      \n      \n        Summer 2025. Graduate student instructor for David Broockman.\n      \n      \n      \n      \n\n      \n      \n        \n          Course Description (click to expand)\n          \n            \n              Government policy deeply influences every aspect of our lives, including the quality of the universities we attend, how much it costs for a gallon of gas, what training we must obtain to take what jobs, what technologies are available to us to use, who we can marry, whether we can afford critical necessities such as housing, and what medical treatments we are allowed or not allowed to obtain. &lt;br&gt; Why do governments make the policies they do? How can advocates craft effective political strategies to influence government policy? &lt;br&gt; This course focuses on understanding the political forces that shape public policy, including interest groups, public pressure, political parties, and voters. In contrast to a public policy course, this course will not consider what ideal public policies should be, but rather consider why governments make the policies they do. &lt;br&gt; This course is suitable for anyone interested in politics or policy. Students will learn tools that will allow them to think like political strategists and understand how they and others influence government in practice.\n            \n          \n        \n      \n\n      \n      \n        \n           Syllabus\n         \n      \n\n      \n      \n        \n           Section Syllabus\n         \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n    \n  \n    \n      PS 109-E: The US Executive Branch and its Political Environment \n      \n      \n      \n      \n        Spring 2025. Graduate student instructor for Sean Gailmard.\n      \n      \n      \n      \n\n      \n      \n        \n          Course Description (click to expand)\n          \n            \n              This course is about how the US government gets things done: the executive branch. Much of what the law actually says is decided in the executive branch, and almost all of it it implemented there. This involves the bureaucracy as well as (often more than) the president. Because implementation of policy defines what policy is, other parts of the government try to influence what the executive branch does, and different parts of the executive branch try to influence each other. &lt;br&gt; The course is structured around three major components. First, we will look at the executive branch with a focus on the president. We will analyze the president’s incentives and constraints in controlling the executive branch, and how presidents’ responses have changed American politics. Second, we will examine the executive branch with a focus on the bureaucracy. We will examine the paths by which bureaucrats make policy, and the ways that other actors try to influence them. Third, we will focus on two case studies to examine the ideas we develop in practice: one on national security and defense policy, one on immigration policy and enforcement.\n            \n          \n        \n      \n\n      \n      \n        \n           Syllabus\n         \n      \n\n      \n      \n        \n           Section Syllabus\n         \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html#tufts-university",
    "href": "teaching/index.html#tufts-university",
    "title": "Teaching",
    "section": "Tufts University",
    "text": "Tufts University\n\n\n\n\n\n  \n    \n      PS 103: Political Science Research Methods \n      \n      \n      \n      \n        Spring 2021. Teaching assistant for Brian Schaffner.\n      \n      \n      \n      \n\n      \n      \n        \n          Course Description (click to expand)\n          \n            \n              Political scientists frequently use quantitative methods to address questions about citizens’ polit- ical attitudes, elections, wars, policy outcomes, and other important political phenomena. This course will consider the general concepts underlying empirical research, including causal inference, research design, statistical analysis, and programming. The goal is to help students become in- formed consumers of quantitative social science research and provide them with useful tools for undertaking empirical research of their own.\n            \n          \n        \n      \n\n      \n      \n        \n           Syllabus\n         \n      \n\n      \n      \n      \n      \n      \n\n      \n      \n      \n      \n      \n      \n    \n  \n\nNo matching items"
  }
]